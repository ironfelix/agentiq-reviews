#!/usr/bin/env python3
"""
Chat AI analyzer â€” takes chat conversations and generates proper AI analysis.
Uses DeepSeek API (OpenAI-compatible), same pattern as llm_analyzer.py.

Usage:
    python scripts/analyze_chats.py [--html path/to/chat-center-real-data.html] [--dry-run]

Reads chatHistory from contextData in HTML, sends each chat to LLM,
writes updated AI fields back into the HTML.
"""

import json
import os
import re
import sys
import time
from typing import Optional

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

MODEL = "deepseek-chat"
MAX_RETRIES = 2

_client = None


def _get_client():
    global _client
    if _client is None:
        if not OPENAI_AVAILABLE:
            raise RuntimeError("openai package not installed. Run: pip install openai")
        api_key = os.getenv("DEEPSEEK_API_KEY")
        if not api_key:
            raise RuntimeError("DEEPSEEK_API_KEY not set")
        _client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")
    return _client


def _call_llm(system_prompt: str, user_prompt: str, max_tokens: int = 1024) -> Optional[str]:
    try:
        cl = _get_client()
    except RuntimeError as e:
        print(f"[LLM] Client init failed: {e}")
        return None

    for attempt in range(MAX_RETRIES + 1):
        try:
            resp = cl.chat.completions.create(
                model=MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                max_tokens=max_tokens,
                temperature=0.3,
            )
            return resp.choices[0].message.content.strip()
        except Exception as e:
            print(f"[LLM] Attempt {attempt+1} failed: {e}")
            if attempt < MAX_RETRIES:
                time.sleep(2 ** attempt)
    return None


# â”€â”€ Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CHAT_SYSTEM = """Ð¢Ñ‹ â€” ÑÐºÑÐ¿ÐµÑ€Ñ‚ Ð¿Ð¾ ÐºÐ¾Ð¼Ð¼ÑƒÐ½Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¾Ð´Ð°Ð²Ñ†Ð° Ñ Ð¿Ð¾ÐºÑƒÐ¿Ð°Ñ‚ÐµÐ»ÑÐ¼Ð¸ Ð½Ð° Wildberries.

Ð—Ð°Ð´Ð°Ñ‡Ð°: Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÐŸÐ•Ð Ð•ÐŸÐ˜Ð¡ÐšÐ£ Ð’ Ð§ÐÐ¢Ð• Ð¼ÐµÐ¶Ð´Ñƒ Ð¿Ð¾ÐºÑƒÐ¿Ð°Ñ‚ÐµÐ»ÐµÐ¼ Ð¸ Ð¿Ñ€Ð¾Ð´Ð°Ð²Ñ†Ð¾Ð¼, Ð¸ Ð´Ð°Ñ‚ÑŒ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑŽ.

ÐŸÐ ÐÐ’Ð˜Ð›Ð ÐÐÐÐ›Ð˜Ð—Ð:
1. Ð§Ð¸Ñ‚Ð°Ð¹ Ð’Ð¡Ð® Ð¿ÐµÑ€ÐµÐ¿Ð¸ÑÐºÑƒ Ñ†ÐµÐ»Ð¸ÐºÐ¾Ð¼, ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ ÐšÐÐ–Ð”ÐžÐ“Ðž ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ.
2. ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸ Ð Ð•ÐÐ›Ð¬ÐÐ£Ð® Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñƒ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° (Ð½Ðµ Ñ†ÐµÐ¿Ð»ÑÐ¹ÑÑ Ð·Ð° ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°).
3. Sentiment Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÐ¹ Ð¿Ð¾ Ð¢ÐžÐÐ£ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°: "!!!", "Ð³Ð´Ðµ Ñ‚Ð¾Ð²Ð°Ñ€???", "Ð¸Ð¼ÐµÐ¹Ñ‚Ðµ ÑÐ¾Ð²ÐµÑÑ‚ÑŒ" = ÐÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ð°Ñ.
4. Urgency = Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ ÐµÑÐ»Ð¸: ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ð·Ð»Ð¸Ñ‚ÑÑ, Ð¼Ð½Ð¾Ð³Ð¾ Ð½ÐµÐ¿Ñ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ð½Ð½Ñ‹Ñ…, Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð°Ñ (Ð±Ñ€Ð°Ðº, Ð¿ÐµÑ€ÐµÑÐ¾Ñ€Ñ‚, Ð´ÐµÐ½ÑŒÐ³Ð¸).
5. AI Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ñ â€” Ð“ÐžÐ¢ÐžÐ’Ð«Ð™ Ð¢Ð•ÐšÐ¡Ð¢ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ Ð»Ð¸Ñ†Ð° Ð¿Ñ€Ð¾Ð´Ð°Ð²Ñ†Ð° (2-3 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ).
6. Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ñ Ð´Ð¾Ð»Ð¶Ð½Ð° Ð¢ÐžÐ§ÐÐž ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ðµ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°.

ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜ Ð’ÐÐ–ÐÐž:
- ÐÐ˜ÐšÐžÐ“Ð”Ð Ð½Ðµ Ð¾Ð±ÐµÑ‰Ð°Ñ‚ÑŒ: Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‚ Ð´ÐµÐ½ÐµÐ³, Ð·Ð°Ð¼ÐµÐ½Ñƒ, ÐºÐ¾Ð¼Ð¿ÐµÐ½ÑÐ°Ñ†Ð¸ÑŽ, ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ ÑÑ€Ð¾ÐºÐ¸ Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ¸.
- ÐŸÑ€ÐµÐ´Ð»Ð°Ð³Ð°Ñ‚ÑŒ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‚ Ñ‡ÐµÑ€ÐµÐ· Ð›Ðš WB Ð¢ÐžÐ›Ð¬ÐšÐž ÐµÑÐ»Ð¸ Ð¿Ð¾ÐºÑƒÐ¿Ð°Ñ‚ÐµÐ»ÑŒ ÑÐ°Ð¼ Ð¿Ñ€Ð¾ÑÐ¸Ñ‚ Ð²ÐµÑ€Ð½ÑƒÑ‚ÑŒ/Ð¾Ð±Ð¼ÐµÐ½ÑÑ‚ÑŒ.
- Ð•ÑÐ»Ð¸ ÐºÐ»Ð¸ÐµÐ½Ñ‚ ÑÐ¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÑ‚ Ð¿Ñ€Ð¾ Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÑƒ â€” ÐÐ• Ð¾Ð±ÐµÑ‰Ð°Ñ‚ÑŒ ÑÑ€Ð¾ÐºÐ¸, ÑÐºÐ°Ð·Ð°Ñ‚ÑŒ Ñ‡Ñ‚Ð¾ Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¸Ð»Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑ.
- Ð•ÑÐ»Ð¸ ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ð¶Ð°Ð»ÑƒÐµÑ‚ÑÑ Ð½Ð° Ð¿ÐµÑ€ÐµÑÐ¾Ñ€Ñ‚/Ð½ÐµÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ â€” Ð¿Ñ€Ð¸Ð·Ð½Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñƒ, ÐÐ• Ð¸Ð³Ð½Ð¾Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ.
- Ð•ÑÐ»Ð¸ Ñ‡Ð°Ñ‚ ÑƒÐ¶Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½ (Ð¿Ñ€Ð¾Ð´Ð°Ð²ÐµÑ† Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ð» Ð°Ð´ÐµÐºÐ²Ð°Ñ‚Ð½Ð¾) â€” Ñ‚Ð°Ðº Ð¸ Ð½Ð°Ð¿Ð¸ÑˆÐ¸.
- ÐÐ˜ÐšÐžÐ“Ð”Ð Ð½Ðµ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ñ‚ÑŒ: Â«Ð˜Ð˜Â», Â«Ð±Ð¾Ñ‚Â», Â«Ð½ÐµÐ¹Ñ€Ð¾ÑÐµÑ‚ÑŒÂ», Â«Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚Â».

Ð¢Ð˜ÐŸÐ« ÐŸÐ ÐžÐ‘Ð›Ð•Ðœ (categories):
- "Ð”Ð¾ÑÑ‚Ð°Ð²ÐºÐ°" â€” Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ°, ÑÑ‚Ð°Ñ‚ÑƒÑ, Ð³Ð´Ðµ Ñ‚Ð¾Ð²Ð°Ñ€
- "Ð‘Ñ€Ð°Ðº / Ð´ÐµÑ„ÐµÐºÑ‚" â€” ÑÐ»Ð¾Ð¼Ð°Ð½Ð¾, Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚
- "ÐŸÐµÑ€ÐµÑÐ¾Ñ€Ñ‚" â€” Ð¿Ñ€Ð¸ÑÐ»Ð°Ð»Ð¸ Ð½Ðµ Ñ‚Ð¾Ñ‚ Ñ‚Ð¾Ð²Ð°Ñ€
- "ÐÐµ Ð¿Ð¾Ð´Ð¾ÑˆÑ‘Ð» Ñ‚Ð¾Ð²Ð°Ñ€" â€” Ñ€Ð°Ð·Ð¼ÐµÑ€, Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ñ‚Ð°
- "Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‚" â€” ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ñ…Ð¾Ñ‡ÐµÑ‚ Ð²ÐµÑ€Ð½ÑƒÑ‚ÑŒ
- "ÐžÑ‚Ð¼ÐµÐ½Ð° Ð·Ð°ÐºÐ°Ð·Ð°" â€” ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ñ…Ð¾Ñ‡ÐµÑ‚ Ð¾Ñ‚Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ
- "Ð“Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ" â€” Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¿Ð¾ Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ð¸
- "Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð¾ Ñ‚Ð¾Ð²Ð°Ñ€Ðµ" â€” Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ¸, ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚ÑŒ
- "ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒ Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼" â€” ÐºÐ°Ðº ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ, Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ
- "Ð‘Ð»Ð°Ð³Ð¾Ð´Ð°Ñ€Ð½Ð¾ÑÑ‚ÑŒ" â€” ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ð´Ð¾Ð²Ð¾Ð»ÐµÐ½
- "ÐžÑˆÐ¸Ð±Ð¾Ñ‡Ð½Ñ‹Ð¹ Ð·Ð°ÐºÐ°Ð·" â€” ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ð½Ðµ Ð·Ð°ÐºÐ°Ð·Ñ‹Ð²Ð°Ð»"""

CHAT_USER = """ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ Ñ‡Ð°Ñ‚-Ð¿ÐµÑ€ÐµÐ¿Ð¸ÑÐºÑƒ.

ÐšÐ»Ð¸ÐµÐ½Ñ‚: {client_name}
Ð¢Ð¾Ð²Ð°Ñ€: {product_name}
ÐÐµÐ¿Ñ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ð½Ð½Ñ‹Ñ…: {unread}

ÐŸÐµÑ€ÐµÐ¿Ð¸ÑÐºÐ°:
{chat_text}

Ð’ÐµÑ€Ð½Ð¸ Ð¡Ð¢Ð ÐžÐ“Ðž JSON (Ð±ÐµÐ· markdown, Ð±ÐµÐ· ```):
{{
  "sentiment": {{
    "label": "ÐŸÐ¾Ð·Ð¸Ñ‚Ð¸Ð²Ð½Ð°Ñ|ÐÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð°Ñ|ÐÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ð°Ñ",
    "negative": true/false
  }},
  "categories": ["ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ1", "ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ2"],
  "urgency": {{
    "label": "Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ Â· Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð°|Ð¡Ñ€ÐµÐ´Ð½ÑÑ Â· Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð°|ÐÐ¸Ð·ÐºÐ°Ñ Â· Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ð°",
    "urgent": true/false
  }},
  "recommendation": "Ð§Ñ‚Ð¾ Ð´ÐµÐ»Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð´Ð°Ð²Ñ†Ñƒ (ÐºÑ€Ð°Ñ‚ÐºÐ¾)",
  "aiSuggestion": "Ð“ÐžÐ¢ÐžÐ’Ð«Ð™ Ð¢Ð•ÐšÐ¡Ð¢ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ Ð»Ð¸Ñ†Ð° Ð¿Ñ€Ð¾Ð´Ð°Ð²Ñ†Ð°. 2-3 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ. Ð•ÑÐ»Ð¸ Ñ‡Ð°Ñ‚ ÑƒÐ¶Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½ Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¿Ñ€Ð¾Ð´Ð°Ð²Ñ†Ð° Ð°Ð´ÐµÐºÐ²Ð°Ñ‚Ð½Ñ‹Ð¹ â€” Ð½Ð°Ð¿Ð¸ÑˆÐ¸ 'Ð§Ð°Ñ‚ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½. ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³.'"
}}"""


# â”€â”€ Guardrails â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

BANNED_PHRASES = [
    "Ð²ÐµÑ€Ð½Ñ‘Ð¼ Ð´ÐµÐ½ÑŒÐ³Ð¸", "Ð²ÐµÑ€Ð½ÐµÐ¼ Ð´ÐµÐ½ÑŒÐ³Ð¸", "Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‚",
    "Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð·Ð°Ð¼ÐµÐ½Ñƒ", "Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‚", "Ð±ÐµÑÐ¿Ð»Ð°Ñ‚Ð½ÑƒÑŽ Ð·Ð°Ð¼ÐµÐ½Ñƒ",
    "Ð²Ñ‹ Ð½ÐµÐ¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾", "Ð²Ñ‹ Ð½Ðµ Ñ‚Ð°Ðº", "Ð²Ð°ÑˆÐ° Ð²Ð¸Ð½Ð°", "ÑÐ°Ð¼Ð¸ Ð²Ð¸Ð½Ð¾Ð²Ð°Ñ‚Ñ‹",
    "Ð˜Ð˜", "Ð±Ð¾Ñ‚", "Ð½ÐµÐ¹Ñ€Ð¾ÑÐµÑ‚", "GPT", "ChatGPT", "Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚",
]


def sanitize(text: str) -> str:
    if not text:
        return text
    for phrase in BANNED_PHRASES:
        text = re.sub(re.escape(phrase), "", text, flags=re.IGNORECASE)
    return text.strip()


# â”€â”€ Extract chats from HTML â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_context_data(html_path: str) -> dict:
    """Extract contextData JS object from HTML file."""
    with open(html_path, "r", encoding="utf-8") as f:
        content = f.read()

    # Find contextData block
    match = re.search(r"const\s+contextData\s*=\s*\{", content)
    if not match:
        raise ValueError("contextData not found in HTML")

    start = match.start()
    # Find matching closing brace
    brace_count = 0
    i = match.end() - 1  # position of opening {
    for i in range(match.end() - 1, len(content)):
        if content[i] == '{':
            brace_count += 1
        elif content[i] == '}':
            brace_count -= 1
            if brace_count == 0:
                break

    js_block = content[match.end()-1:i+1]

    # Convert JS object to valid JSON-ish â€” we'll parse it differently
    # Since it's complex JS with single quotes, we parse key fields manually
    return _parse_chats_from_js(js_block, content, start, i+1)


def _parse_chats_from_js(js_block: str, full_content: str, ctx_start: int, ctx_end: int):
    """Parse chat data from JS contextData block."""
    chats = {}

    # Find each chat ID block: '1': { ... }
    chat_pattern = re.compile(r"'(\d+)':\s*\{")
    for m in chat_pattern.finditer(js_block):
        chat_id = m.group(1)

        # Find this chat's data boundaries
        start_pos = m.end() - 1
        brace_count = 0
        end_pos = start_pos
        for j in range(start_pos, len(js_block)):
            if js_block[j] == '{':
                brace_count += 1
            elif js_block[j] == '}':
                brace_count -= 1
                if brace_count == 0:
                    end_pos = j
                    break

        chat_block = js_block[start_pos:end_pos+1]

        # Extract fields
        chat = {
            'id': chat_id,
            'client_name': _extract_field(chat_block, 'title'),
            'product_name': _extract_field(chat_block, 'name') or 'ÐÐµ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ñ‘Ð½',
            'article': _extract_field(chat_block, 'article'),
            'unread': _extract_field(chat_block, 'unread') or '0',
            'messages': _extract_messages(chat_block),
            'has_seller_reply': 'seller' in chat_block and "'type': 'seller'" in chat_block.replace('"', "'"),
        }
        chats[chat_id] = chat

    return chats, full_content, ctx_start, ctx_end


def _extract_field(block: str, field_name: str) -> Optional[str]:
    """Extract a simple string field from JS object."""
    patterns = [
        rf"{field_name}:\s*'([^']*)'",
        rf"{field_name}:\s*\"([^\"]*)\"",
    ]
    for p in patterns:
        m = re.search(p, block)
        if m:
            val = m.group(1)
            return val if val != 'null' else None
    return None


def _extract_messages(block: str) -> list:
    """Extract chatHistory messages from JS block."""
    messages = []

    # Find chatHistory array
    hist_match = re.search(r"chatHistory:\s*\[", block)
    if not hist_match:
        return messages

    # Find matching ]
    bracket_start = hist_match.end() - 1
    bracket_count = 0
    bracket_end = bracket_start
    for j in range(bracket_start, len(block)):
        if block[j] == '[':
            bracket_count += 1
        elif block[j] == ']':
            bracket_count -= 1
            if bracket_count == 0:
                bracket_end = j
                break

    hist_block = block[bracket_start+1:bracket_end]

    # Extract each message object
    msg_pattern = re.compile(r"\{\s*type:\s*'(\w+)'")
    for m in msg_pattern.finditer(hist_block):
        msg_type = m.group(1)
        # Find this message's closing brace
        msg_start = m.start()
        bc = 0
        msg_end = msg_start
        for j in range(msg_start, len(hist_block)):
            if hist_block[j] == '{':
                bc += 1
            elif hist_block[j] == '}':
                bc -= 1
                if bc == 0:
                    msg_end = j
                    break

        msg_block = hist_block[msg_start:msg_end+1]

        if msg_type == 'date':
            text = _extract_field(msg_block, 'text') or ''
            messages.append(f"[{text}]")
        elif msg_type in ('customer', 'seller'):
            author = _extract_field(msg_block, 'author') or msg_type
            text = _extract_field(msg_block, 'text') or ''
            time_val = _extract_field(msg_block, 'time') or ''
            if text:
                messages.append(f"{author} ({time_val}): {text}")

    return messages


# â”€â”€ Analyze single chat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def analyze_chat(chat: dict) -> Optional[dict]:
    """Send chat to LLM, get structured analysis."""
    chat_text = "\n".join(chat['messages']) if chat['messages'] else "(Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ñ‡Ð°Ñ‚)"

    user_prompt = CHAT_USER.format(
        client_name=chat['client_name'] or 'ÐšÐ»Ð¸ÐµÐ½Ñ‚',
        product_name=chat['product_name'],
        unread=chat['unread'],
        chat_text=chat_text,
    )

    raw = _call_llm(CHAT_SYSTEM, user_prompt, max_tokens=512)
    if not raw:
        return None

    # Clean markdown wrappers
    raw = re.sub(r'^```json\s*', '', raw)
    raw = re.sub(r'\s*```$', '', raw)

    try:
        result = json.loads(raw)
    except json.JSONDecodeError:
        # Try to extract JSON from response
        json_match = re.search(r'\{[\s\S]*\}', raw)
        if json_match:
            try:
                result = json.loads(json_match.group())
            except json.JSONDecodeError:
                print(f"  [WARN] Failed to parse JSON for chat {chat['id']}")
                return None
        else:
            print(f"  [WARN] No JSON found for chat {chat['id']}")
            return None

    # Sanitize
    if 'aiSuggestion' in result:
        result['aiSuggestion'] = sanitize(result['aiSuggestion'])

    return result


# â”€â”€ Update HTML â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def update_html(html_path: str, results: dict, dry_run: bool = False):
    """Update AI fields in contextData within the HTML file."""
    with open(html_path, "r", encoding="utf-8") as f:
        content = f.read()

    for chat_id, analysis in results.items():
        if not analysis:
            continue

        # Update aiSuggestion
        ai_suggestion = analysis.get('aiSuggestion', '')
        content = _replace_field_in_chat(content, chat_id, 'aiSuggestion', f"'{_escape_js(ai_suggestion)}'")

        # Update ai object fields
        sentiment = analysis.get('sentiment', {})
        categories = analysis.get('categories', [])
        urgency = analysis.get('urgency', {})
        recommendation = analysis.get('recommendation', '')

        # Build new ai object
        sentiment_label = sentiment.get('label', 'ÐÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð°Ñ')
        sentiment_negative = 'true' if sentiment.get('negative', False) else 'false'
        cats_str = ', '.join(f"'{c}'" for c in categories)
        urgency_label = urgency.get('label', 'Ð¡Ñ€ÐµÐ´Ð½ÑÑ')
        urgency_urgent = 'true' if urgency.get('urgent', False) else 'false'

        new_ai = (
            f"{{ sentiment: {{ label: '{_escape_js(sentiment_label)}', negative: {sentiment_negative} }}, "
            f"categories: [{cats_str}], "
            f"urgency: {{ label: '{_escape_js(urgency_label)}', urgent: {urgency_urgent} }}, "
            f"recommendation: '{_escape_js(recommendation)}' }}"
        )

        content = _replace_field_in_chat(content, chat_id, 'ai', new_ai)

    if dry_run:
        print("\n[DRY RUN] Would write updated HTML. Showing first result as sample.")
        first_id = next(iter(results))
        if results[first_id]:
            print(json.dumps(results[first_id], indent=2, ensure_ascii=False))
    else:
        with open(html_path, "w", encoding="utf-8") as f:
            f.write(content)
        print(f"\n[OK] Updated {html_path}")


def _escape_js(s: str) -> str:
    """Escape string for JS single-quoted string."""
    return s.replace("\\", "\\\\").replace("'", "\\'").replace("\n", "\\n")


def _replace_field_in_chat(content: str, chat_id: str, field: str, new_value: str) -> str:
    """Replace a field value in a specific chat's contextData entry."""
    # Find the chat block by its ID
    chat_start_pattern = rf"'{chat_id}':\s*\{{"
    chat_match = re.search(chat_start_pattern, content)
    if not chat_match:
        return content

    # Search for the field within this chat block (limited scope)
    search_start = chat_match.end()

    if field == 'aiSuggestion':
        # aiSuggestion: 'text here',
        field_pattern = rf"(aiSuggestion:\s*)'(?:[^'\\]|\\.)*'"
        m = re.search(field_pattern, content[search_start:search_start+2000])
        if m:
            old = content[search_start + m.start():search_start + m.end()]
            new = f"{m.group(1)}{new_value}"
            content = content[:search_start + m.start()] + new + content[search_start + m.end():]
    elif field == 'ai':
        # ai: { ... }
        field_pattern = r"ai:\s*\{"
        m = re.search(field_pattern, content[search_start:search_start+3000])
        if m:
            # Find matching closing brace
            pos = search_start + m.end() - 1
            bc = 0
            end_pos = pos
            for j in range(pos, min(pos + 1000, len(content))):
                if content[j] == '{':
                    bc += 1
                elif content[j] == '}':
                    bc -= 1
                    if bc == 0:
                        end_pos = j
                        break
            old_ai_start = search_start + m.start()
            content = content[:old_ai_start] + f"ai: {new_value}" + content[end_pos+1:]

    return content


# â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    import argparse
    parser = argparse.ArgumentParser(description="Analyze chat conversations with LLM")
    parser.add_argument("--html", default="docs/chat-center/chat-center-real-data.html",
                        help="Path to HTML file with contextData")
    parser.add_argument("--dry-run", action="store_true", help="Don't modify HTML, just print results")
    parser.add_argument("--chat-id", type=str, help="Analyze only specific chat ID")
    args = parser.parse_args()

    # Resolve path
    html_path = args.html
    if not os.path.isabs(html_path):
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_dir = os.path.dirname(script_dir)
        html_path = os.path.join(project_dir, html_path)

    print(f"[*] Reading chats from: {html_path}")
    chats, full_content, ctx_start, ctx_end = extract_context_data(html_path)
    print(f"[*] Found {len(chats)} chats")

    if args.chat_id:
        if args.chat_id not in chats:
            print(f"[ERROR] Chat ID {args.chat_id} not found")
            sys.exit(1)
        chats = {args.chat_id: chats[args.chat_id]}

    results = {}
    for chat_id, chat in sorted(chats.items(), key=lambda x: int(x[0])):
        msgs_count = len([m for m in chat['messages'] if not m.startswith('[')])
        print(f"  Chat #{chat_id}: {chat['client_name']} â€” {msgs_count} msgs, product: {chat['product_name']}")

        analysis = analyze_chat(chat)
        if analysis:
            sent = analysis.get('sentiment', {}).get('label', '?')
            cats = ', '.join(analysis.get('categories', []))
            urgent = 'ðŸ”´' if analysis.get('urgency', {}).get('urgent') else 'âšª'
            suggestion_preview = (analysis.get('aiSuggestion', '')[:80] + '...') if len(analysis.get('aiSuggestion', '')) > 80 else analysis.get('aiSuggestion', '')
            print(f"    {urgent} Sentiment: {sent} | Categories: {cats}")
            print(f"    â†’ {suggestion_preview}")
        else:
            print(f"    [SKIP] LLM returned no result")

        results[chat_id] = analysis
        time.sleep(0.5)  # rate limit

    success = sum(1 for v in results.values() if v)
    print(f"\n[*] Analyzed: {success}/{len(chats)} chats")

    if success > 0:
        update_html(html_path, results, dry_run=args.dry_run)


if __name__ == "__main__":
    main()
