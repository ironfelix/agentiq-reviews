#!/usr/bin/env python3
import json
import os
import re
import sys
from collections import Counter, defaultdict
from datetime import datetime, timezone, timedelta
from urllib.request import urlopen, Request
from urllib.error import URLError

try:
    from dotenv import load_dotenv
    # Load .env from apps/reviews (where credentials live)
    _env_path = os.path.join(
        os.path.dirname(os.path.abspath(__file__)),
        "..",
        "apps",
        "reviews",
        ".env",
    )
    if os.path.exists(_env_path):
        load_dotenv(_env_path)
except ImportError:
    pass

try:
    from llm_analyzer import llm_classify_reasons, llm_get_actions, llm_get_reply_template, llm_deep_analysis, llm_analyze_communication
    LLM_AVAILABLE = True
except ImportError:
    LLM_AVAILABLE = False

WINDOW_DAYS = 30
MIN_REVIEWS_FOR_SIGNAL = 5   # Minimum reviews per variant to consider it for signal
MIN_GAP_FOR_SIGNAL = 0.3     # Minimum rating gap vs others to trigger signal


# ‚îÄ‚îÄ‚îÄ WB card description API ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _wb_basket_num(nm_id: int) -> str:
    """Determine WB basket server number from nmId."""
    vol = nm_id // 100000
    ranges = [
        (143, "01"), (287, "02"), (431, "03"), (719, "04"),
        (1007, "05"), (1061, "06"), (1115, "07"), (1169, "08"),
        (1313, "09"), (1601, "10"), (1655, "11"), (1919, "12"),
        (2045, "13"), (2189, "14"), (2405, "15"), (2621, "16"),
        (2837, "17"), (3053, "18"), (3269, "19"), (3485, "20"),
        (3701, "21"), (3917, "22"), (4133, "23"), (4349, "24"),
        (4565, "25"),
    ]
    for threshold, num in ranges:
        if vol <= threshold:
            return num
    return "26"


def fetch_wb_card_info(nm_id: int):
    """Fetch product card from WB public API (no auth needed).

    Returns dict with keys: imt_name, description, options, subj_name
    or None on any error.
    """
    try:
        nm_id = int(nm_id)
    except (TypeError, ValueError):
        return None

    vol = nm_id // 100000
    part = nm_id // 1000
    basket = _wb_basket_num(nm_id)
    url = f"https://basket-{basket}.wbbasket.ru/vol{vol}/part{part}/{nm_id}/info/ru/card.json"

    try:
        req = Request(url, headers={"User-Agent": "Mozilla/5.0"})
        with urlopen(req, timeout=5) as resp:
            data = json.loads(resp.read().decode())
    except (URLError, json.JSONDecodeError, OSError) as e:
        print(f"[WB card] Failed to fetch {nm_id}: {e}")
        return None

    description = data.get("description", "")
    options_raw = data.get("options", [])
    options_str = "; ".join(
        f"{o['name']}: {o['value']}" for o in options_raw
        if o.get("name") and o.get("value")
    )

    # Extract price from sizes[0].price (in kopeks)
    # Prefer 'product' (sale price) > 'total' (with WB wallet) > 'basic' (full price)
    price_kopeks = 0
    sizes = data.get("sizes", [])
    if sizes and isinstance(sizes, list):
        price_data = sizes[0].get("price", {})
        price_kopeks = price_data.get("product") or price_data.get("total") or price_data.get("basic", 0)
    price_rub = round(price_kopeks / 100, 2) if price_kopeks else None

    result = {
        "imt_name": data.get("imt_name", ""),
        "description": description,
        "options": options_str,
        "subj_name": data.get("subj_name", ""),
        "price": price_rub,
    }
    print(f"[WB card] OK: {result['imt_name'][:60]}, price: {price_rub}‚ÇΩ")
    return result


def fetch_wb_price_history(nm_id: int):
    """Fetch price history from WB CDN (no auth needed).

    URL: basket-{N}.wbbasket.ru/vol{V}/part{P}/{nmId}/info/price-history.json
    Returns list of {"dt": unix_ts, "price_rub": float} sorted by date,
    or None on error.
    Prices in the API are in kopecks (√∑100 for rubles).
    """
    try:
        nm_id = int(nm_id)
    except (TypeError, ValueError):
        return None

    vol = nm_id // 100000
    part = nm_id // 1000
    basket = _wb_basket_num(nm_id)
    url = f"https://basket-{basket}.wbbasket.ru/vol{vol}/part{part}/{nm_id}/info/price-history.json"

    try:
        req = Request(url, headers={"User-Agent": "Mozilla/5.0", "Accept-Encoding": "gzip"})
        with urlopen(req, timeout=5) as resp:
            raw = resp.read()
            # Handle gzip encoding
            if resp.headers.get("Content-Encoding") == "gzip":
                import gzip
                raw = gzip.decompress(raw)
            data = json.loads(raw.decode())
    except (URLError, json.JSONDecodeError, OSError) as e:
        print(f"[WB price] Failed to fetch {nm_id}: {e}")
        return None

    if not isinstance(data, list) or len(data) == 0:
        return None

    result = []
    for entry in data:
        dt = entry.get("dt")
        price_info = entry.get("price", {})
        rub_kopecks = price_info.get("RUB", 0)
        if dt and rub_kopecks:
            result.append({
                "dt": dt,
                "price_rub": round(rub_kopecks / 100, 2),
            })

    result.sort(key=lambda x: x["dt"])
    if result:
        print(f"[WB price] OK: {len(result)} data points, latest: {result[-1]['price_rub']}‚ÇΩ")
    return result if result else None


def avg_price_from_history(price_history, months=3):
    """Calculate average price from last N months of price history.

    Returns float (average price in rubles) or None.
    """
    if not price_history:
        return None

    import time
    now = time.time()
    cutoff = now - (months * 30 * 86400)

    recent = [p["price_rub"] for p in price_history if p["dt"] >= cutoff]
    if not recent:
        # Fall back to all data
        recent = [p["price_rub"] for p in price_history]
    if not recent:
        return None

    return round(sum(recent) / len(recent), 2)


def calculate_money_loss(review_count, period_months, price_rub, quality_score):
    """Calculate estimated money loss from poor communication quality.

    Args:
        review_count: Total reviews received
        period_months: Period in months
        price_rub: Product price in rubles
        quality_score: LLM quality score (1-10)

    Returns:
        {
            "purchases_per_month_min": int,
            "purchases_per_month_max": int,
            "revenue_per_month_min": int,
            "revenue_per_month_max": int,
            "loss_per_month_min": int,
            "loss_per_month_max": int,
        }
        or None if price is not available
    """
    if not price_rub or price_rub <= 0:
        return None

    # Review rate assumptions (3-5% for functional products)
    review_rate_min = 0.03
    review_rate_max = 0.05

    # Calculate purchases
    total_purchases_min = int(review_count / review_rate_max)  # conservative
    total_purchases_max = int(review_count / review_rate_min)  # optimistic

    purchases_per_month_min = int(total_purchases_min / period_months)
    purchases_per_month_max = int(total_purchases_max / period_months)

    # Calculate revenue
    revenue_per_month_min = int(purchases_per_month_min * price_rub)
    revenue_per_month_max = int(purchases_per_month_max * price_rub)

    # CR impact based on quality score (inverse relationship)
    # Note: risky weight = 1 (not 2), harm index calculation adjusted accordingly
    cr_impact_min = 0.02  # 2% for quality 4-6
    cr_impact_max = 0.04  # 4% for quality 1-3

    if quality_score >= 7:
        cr_impact_min, cr_impact_max = 0.01, 0.02
    elif quality_score >= 4:
        cr_impact_min, cr_impact_max = 0.02, 0.04
    else:
        cr_impact_min, cr_impact_max = 0.03, 0.06

    # Calculate losses
    loss_per_month_min = int(revenue_per_month_min * cr_impact_min)
    loss_per_month_max = int(revenue_per_month_max * cr_impact_max)

    return {
        "purchases_per_month_min": purchases_per_month_min,
        "purchases_per_month_max": purchases_per_month_max,
        "revenue_per_month_min": revenue_per_month_min,
        "revenue_per_month_max": revenue_per_month_max,
        "loss_per_month_min": loss_per_month_min,
        "loss_per_month_max": loss_per_month_max,
        "price_rub": round(price_rub),
        "review_count": review_count,
        "period_months": period_months,
        "conversion_loss_pct_min": round(cr_impact_min * 100),
        "conversion_loss_pct_max": round(cr_impact_max * 100),
    }


# ‚îÄ‚îÄ‚îÄ WBCON Questions API ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def fetch_wbcon_questions(nm_id, email, password):
    # type: (int, str, str) -> list
    """Fetch customer questions from WBCON QS API.

    Creates a task, polls for completion, then retrieves results.
    Returns list of question dicts or empty list on any error.
    Timeout: 120 seconds total for polling.
    """
    qs_base = os.getenv("WBCON_QS_BASE", "https://qs.wbcon.su")

    # 1. Create task
    print(f"[WBCON QS] Creating task for article {nm_id}...")
    create_url = f"{qs_base}/create_task_qs?email={email}&password={password}"
    body = json.dumps({"article": int(nm_id)}).encode("utf-8")
    try:
        req = Request(create_url, data=body, method="POST",
                      headers={"Content-Type": "application/json"})
        with urlopen(req, timeout=10) as resp:
            create_data = json.loads(resp.read().decode())
    except (URLError, json.JSONDecodeError, OSError) as e:
        print(f"[WBCON QS] Failed to create task: {e}")
        return []

    task_id = create_data.get("task_id")
    if not task_id:
        print(f"[WBCON QS] No task_id in response: {create_data}")
        return []
    print(f"[WBCON QS] Task created: {task_id}")

    # 2. Poll for status (max 120 seconds, 5s interval = 24 attempts)
    import time as _time
    deadline = _time.time() + 120
    while _time.time() < deadline:
        status_url = f"{qs_base}/task_status?task_id={task_id}&email={email}&password={password}"
        try:
            req = Request(status_url, headers={"User-Agent": "Mozilla/5.0"})
            with urlopen(req, timeout=10) as resp:
                status_data = json.loads(resp.read().decode())
        except (URLError, json.JSONDecodeError, OSError) as e:
            print(f"[WBCON QS] Status check failed: {e}")
            _time.sleep(5)
            continue

        if status_data.get("is_ready"):
            break

        error = status_data.get("error", "")
        if error:
            print(f"[WBCON QS] Task error: {error}")
            return []

        _time.sleep(5)
    else:
        print("[WBCON QS] Timeout waiting for task to complete (120s)")
        return []

    # 3. Get results
    results_url = f"{qs_base}/get_results_qs?task_id={task_id}&email={email}&password={password}"
    try:
        req = Request(results_url, headers={"User-Agent": "Mozilla/5.0"})
        with urlopen(req, timeout=10) as resp:
            results_data = json.loads(resp.read().decode())
    except (URLError, json.JSONDecodeError, OSError) as e:
        print(f"[WBCON QS] Failed to get results: {e}")
        return []

    # Response is a list; questions are in the first element
    questions = []
    if isinstance(results_data, list) and results_data:
        questions = results_data[0].get("questions", [])
    elif isinstance(results_data, dict):
        questions = results_data.get("questions", [])

    print(f"[WBCON QS] Got {len(questions)} questions")
    return questions


COLOR_WORDS = (
    "–∫—Ä–∞—Å–Ω", "—Å–∏–Ω", "—Å–µ—Ä", "—á–µ—Ä–Ω", "–±–µ–ª", "–∑–µ–ª", "–∂–µ–ª—Ç", "—Ä–æ–∑",
    "—Ñ–∏–æ–ª–µ—Ç", "–≥–æ–ª—É–±", "–æ—Ä–∞–Ω–∂", "–±–µ–∂", "—Ö–∞–∫–∏", "–±–æ—Ä–¥–æ", "–∫–æ—Ä–∏—á–Ω",
    "—Å–µ—Ä–µ–±", "–∑–æ–ª–æ—Ç"
)
NON_COLOR_HINTS = ("—à—Ç", "–º", "–º–º", "—Å–º", "–ª", "–º–ª", "–ª—é–º", "–∫–≥", "–≥—Ä", "–Ω–∞–±–æ—Ä", "–∫–æ–º–ø–ª–µ–∫—Ç")

# –ê–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é —Ç–æ–≤–∞—Ä–∞
CATEGORY_KEYWORDS = {
    "flashlight": ["—Ñ–æ–Ω–∞—Ä", "–Ω–∞–ª–æ–±–Ω", "–ø—Ä–æ–∂–µ–∫—Ç–æ—Ä", "—Å–≤–µ—Ç–æ–¥–∏–æ–¥"],
    "clothing": ["–ø–ª–∞—Ç—å–µ", "–∫—É—Ä—Ç–∫–∞", "–±—Ä—é–∫–∏", "—Ñ—É—Ç–±–æ–ª–∫", "–æ–¥–µ–∂–¥", "—Ä–∞–∑–º–µ—Ä", "–¥–∂–∏–Ω—Å", "–ø–∞–ª—å—Ç–æ", "—Å–≤–∏—Ç–µ—Ä"],
    "electronics": ["–Ω–∞—É—à–Ω–∏–∫", "–∫–æ–ª–æ–Ω–∫", "–∑–∞—Ä—è–¥–∫", "–∫–∞–±–µ–ª—å", "—Å–º–∞—Ä—Ç—Ñ–æ–Ω", "–ø–ª–∞–Ω—à–µ—Ç", "—á–∞—Å—ã", "bluetooth"],
    "pet_food": ["–∫–æ—Ä–º", "–∫–æ—à–∫", "—Å–æ–±–∞–∫", "–ø–∏—Ç–æ–º", "–∂–∏–≤–æ—Ç–Ω", "–ª–∞–∫–æ–º—Å—Ç–≤", "–≤–∫—É—Å"],
    "kitchen": ["—á–∞–π–Ω–∏–∫", "–∫–∞—Å—Ç—Ä—é–ª", "—Å–∫–æ–≤–æ—Ä–æ–¥", "—Ç–µ—Ä–º–æ—Å", "—Ç–µ—Ä–º–æ–∫—Ä—É–∂–∫",
                "–±–ª–µ–Ω–¥–µ—Ä", "–º–∏–∫—Å–µ—Ä", "—Ç–æ—Å—Ç–µ—Ä", "–º–∏–∫—Ä–æ–≤–æ–ª–Ω", "–º—É–ª—å—Ç–∏–≤–∞—Ä–∫",
                "–∫–æ—Ñ–µ–≤–∞—Ä", "—á–∞–π–Ω—ã–π", "–∫–∏–ø—è—Ç", "–ª–∏—Ç—Ä", "—ç–ª–µ–∫—Ç—Ä–æ—á–∞–π–Ω"],
    "home": ["–ø–æ—Å—Ç–µ–ª—å", "–ø–æ–ª–æ—Ç–µ–Ω—Ü", "–ø–æ–¥—É—à–∫", "–æ–¥–µ—è–ª–æ", "–ø–ª–µ–¥",
             "—à—Ç–æ—Ä", "–∫–æ–≤—Ä", "–º–∞—Ç—Ä–∞—Å", "–ø–æ–∫—Ä—ã–≤–∞–ª", "–Ω–∞–≤–æ–ª–æ—á"],
    "beauty": ["–∫—Ä–µ–º", "–º–∞—Å–∫–∞", "—à–∞–º–ø—É–Ω—å", "–∫–æ—Å–º–µ—Ç–∏–∫", "–ø–æ–º–∞–¥",
               "—Ç—É—à—å", "–ø—É–¥—Ä", "—Ç–æ–Ω–∞–ª—å", "—Å—ã–≤–æ—Ä–æ—Ç–∫", "–±–∞–ª—å–∑–∞–º"],
    "toys": ["–∏–≥—Ä—É—à–∫", "–∫—É–∫–ª", "–∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä", "–º–∞—à–∏–Ω–∫", "–ø–∞–∑–ª",
             "–º—è–≥–∫", "–ø–ª—é—à–µ–≤", "–ª–µ–≥–æ", "—Ä–æ–±–æ—Ç"],
    "auto": ["–∞–≤—Ç–æ–º–æ–±–∏–ª", "–º–∞—à–∏–Ω", "—Ä—É–ª—å", "–±–∞–º–ø–µ—Ä", "—Ñ–∞—Ä",
             "–≤–∏–¥–µ–æ—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ç–æ—Ä", "–Ω–∞–≤–∏–≥–∞—Ç–æ—Ä", "–∞–≤—Ç–æ–º–æ–π–∫"],
    "sports": ["–≥–∞–Ω—Ç–µ–ª", "–∫–æ–≤—Ä–∏–∫", "—Ç—Ä–µ–Ω–∞–∂–µ—Ä", "–º—è—á", "—Å–∫–∞–∫–∞–ª–∫",
               "—Ñ–∏—Ç–Ω–µ—Å", "–π–æ–≥–∞", "–≤–µ–ª–æ—Å–∏–ø–µ–¥", "—Å–∞–º–æ–∫–∞—Ç"],
}

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# REASONS: –≥–∏–±—Ä–∏–¥–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ + –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—ã–µ)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã ‚Äî —Ä–∞–±–æ—Ç–∞—é—Ç –¥–ª—è –ª—é–±—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
UNIVERSAL_REASONS = {
    "defect": {
        "label": "–ë—Ä–∞–∫ / –¥–µ—Ñ–µ–∫—Ç",
        "emoji": "üîß",
        "patterns": ["–±—Ä–∞–∫", "–¥–µ—Ñ–µ–∫—Ç", "—Å–ª–æ–º–∞–ª", "—Å–ª–æ–º–∞–Ω", "–Ω–µ —Ä–∞–±–æ—Ç–∞", "–Ω–µ–∏—Å–ø—Ä–∞–≤"],
    },
    "mismatch": {
        "label": "–ù–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—é",
        "emoji": "üìã",
        "patterns": ["–Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤", "–æ–ø–∏—Å–∞–Ω–∏", "–æ–∂–∏–¥–∞–ª", "–¥—É–º–∞–ª", "–Ω–∞ —Ñ–æ—Ç–æ", "–ø–æ —Ñ–∞–∫—Ç—É"],
    },
    "delivery": {
        "label": "–ü–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ –¥–æ—Å—Ç–∞–≤–∫–µ",
        "emoji": "üì¶",
        "patterns": ["–¥–æ—Å—Ç–∞–≤–∫", "–ø–æ–º—è—Ç", "—É–ø–∞–∫–æ–≤–∫", "–ø–æ–≤—Ä–µ–∂", "–ø—Ä–∏—à–ª", "–∫—É—Ä—å–µ—Ä"],
    },
}

# –ö–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—ã–µ –ø—Ä–µ—Å–µ—Ç—ã ‚Äî –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è —Å–≤–µ—Ä—Ö—É –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –Ω–∏—à
CATEGORY_PRESETS = {
    "flashlight": {
        "brightness": {
            "label": "–°–≤–µ—Ç–∏—Ç —Å–ª–∞–±–µ–µ, —á–µ–º –æ–∂–∏–¥–∞–ª–∏",
            "emoji": "üí°",
            "patterns": ["—Å–≤–µ—Ç", "—è—Ä–∫", "—Ç—É—Å–∫", "—Å–ª–∞–±", "–ª—é–º–µ–Ω", "—Ç–µ–º–Ω"],
        },
        "battery": {
            "label": "–ë—ã—Å—Ç—Ä–æ —Å–∞–¥–∏—Ç—Å—è –∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä",
            "emoji": "üîã",
            "patterns": ["–∞–∫–∫—É–º", "–∑–∞—Ä—è–¥", "—Å–∞–¥–∏—Ç", "—Ä–∞–∑—Ä—è–¥", "–±–∞—Ç–∞—Ä", "–¥–µ—Ä–∂"],
        },
        "waterproof": {
            "label": "–ù–µ –¥–µ—Ä–∂–∏—Ç –≤–æ–¥—É / –≤–ª–∞–≥—É",
            "emoji": "üíß",
            "patterns": ["–≤–æ–¥", "–≤–ª–∞–≥", "–ø—Ä–æ–º–æ–∫", "–∑–∞–ª–∏–ª", "–≥–µ—Ä–º–µ—Ç–∏—á"],
        },
        "build": {
            "label": "–ö–∞—á–µ—Å—Ç–≤–æ —Å–±–æ—Ä–∫–∏",
            "emoji": "üî©",
            "patterns": ["—Å–±–æ—Ä–∫", "–ª—é—Ñ—Ç", "—Å–∫—Ä–∏–ø", "–±–æ–ª—Ç–∞–µ—Ç", "—Ö–ª–∏–ø–∫", "–ø–ª–∞—Å—Ç–∏–∫"],
        },
    },
    "clothing": {
        "size": {
            "label": "–ù–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ä–∞–∑–º–µ—Ä—É",
            "emoji": "üìè",
            "patterns": ["—Ä–∞–∑–º–µ—Ä", "–º–∞–ª", "–≤–µ–ª–∏–∫", "—É–∑–∫", "—à–∏—Ä–æ–∫", "–∫–æ—Ä–æ—Ç–∫", "–¥–ª–∏–Ω–Ω"],
        },
        "fabric": {
            "label": "–ö–∞—á–µ—Å—Ç–≤–æ —Ç–∫–∞–Ω–∏",
            "emoji": "üßµ",
            "patterns": ["—Ç–∫–∞–Ω—å", "–º–∞—Ç–µ—Ä–∏–∞–ª", "—Ç–æ–Ω–∫", "–ø—Ä–æ—Å–≤–µ—á", "–ª–∏–Ω—è–µ—Ç", "–∫–∞—Ç—ã—à"],
        },
        "color_mismatch": {
            "label": "–¶–≤–µ—Ç –Ω–µ –∫–∞–∫ –Ω–∞ —Ñ–æ—Ç–æ",
            "emoji": "üé®",
            "patterns": ["—Ü–≤–µ—Ç", "–æ—Ç—Ç–µ–Ω–æ–∫", "—Ñ–æ—Ç–æ", "–∫–∞—Ä—Ç–∏–Ω–∫", "—Ç–µ–º–Ω–µ–µ", "—Å–≤–µ—Ç–ª–µ–µ"],
        },
        "smell": {
            "label": "–ù–µ–ø—Ä–∏—è—Ç–Ω—ã–π –∑–∞–ø–∞—Ö",
            "emoji": "üëÉ",
            "patterns": ["–∑–∞–ø–∞—Ö", "–≤–æ–Ω—è–µ—Ç", "–ø–∞—Ö–Ω–µ—Ç", "—Ö–∏–º–∏—è", "–≤–æ–Ω—å"],
        },
    },
    "electronics": {
        "battery": {
            "label": "–ü—Ä–æ–±–ª–µ–º—ã —Å –±–∞—Ç–∞—Ä–µ–µ–π",
            "emoji": "üîã",
            "patterns": ["–∞–∫–∫—É–º", "–∑–∞—Ä—è–¥", "–±–∞—Ç–∞—Ä", "—Ä–∞–∑—Ä—è–¥", "–¥–µ—Ä–∂"],
        },
        "connectivity": {
            "label": "–ü—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º",
            "emoji": "üì∂",
            "patterns": ["–ø–æ–¥–∫–ª—é—á", "bluetooth", "wifi", "—Å–≤—è–∑—å", "—Å–æ–ø—Ä—è–∂", "–æ—Ç–∫–ª—é—á"],
        },
        "sound": {
            "label": "–ü—Ä–æ–±–ª–µ–º—ã —Å–æ –∑–≤—É–∫–æ–º",
            "emoji": "üîä",
            "patterns": ["–∑–≤—É–∫", "–≥—Ä–æ–º–∫", "—Ç–∏—Ö", "—Ö—Ä–∏–ø", "—à—É–º", "–¥–∏–Ω–∞–º–∏–∫"],
        },
    },
    "pet_food": {
        "flavor_mismatch": {
            "label": "–ü—Ä–∏—Å–ª–∞–ª–∏ –Ω–µ —Ç–æ—Ç –≤–∫—É—Å",
            "emoji": "üîÑ",
            "patterns": ["–Ω–µ —Ç–æ—Ç", "–¥—Ä—É–≥–æ–π –≤–∫—É—Å", "–ø–µ—Ä–µ–ø—É—Ç–∞–ª", "–∑–∞–∫–∞–∑—ã–≤–∞–ª", "–≤–º–µ—Å—Ç–æ", "–æ–∂–∏–¥–∞–ª", "–ø—Ä–∏—Å–ª–∞–ª–∏"],
        },
        "pet_rejection": {
            "label": "–ü–∏—Ç–æ–º–µ—Ü –Ω–µ –µ—Å—Ç",
            "emoji": "üê±",
            "patterns": ["–Ω–µ –µ—Å—Ç", "–Ω–µ —Å—Ç–∞–ª", "–æ—Ç–∫–∞–∑", "–Ω–µ –Ω—Ä–∞–≤", "–≤—ã–ø–ª–µ–≤", "–ø–æ–Ω—é—Ö–∞–ª"],
        },
        "packaging": {
            "label": "–ü—Ä–æ–±–ª–µ–º—ã —Å —É–ø–∞–∫–æ–≤–∫–æ–π",
            "emoji": "üì¶",
            "patterns": ["—É–ø–∞–∫–æ–≤", "–ø–æ—Ä–≤–∞–Ω", "—Ä–≤–∞–Ω—ã–π", "–æ—Ç–∫—Ä—ã—Ç", "–ø–æ–º—è—Ç", "–ø—Ä–æ—Å—ã–ø"],
        },
        "freshness": {
            "label": "–ö–∞—á–µ—Å—Ç–≤–æ / —Å–≤–µ–∂–µ—Å—Ç—å",
            "emoji": "üïê",
            "patterns": ["—Å—Ä–æ–∫", "–ø—Ä–æ—Å—Ä–æ—á", "–∑–∞–ø–∞—Ö", "–ø–ª–µ—Å–µ–Ω", "–∏—Å–ø–æ—Ä—á", "—Å—Ç–∞—Ä—ã–π"],
        },
        "composition": {
            "label": "–°–æ—Å—Ç–∞–≤ –Ω–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç",
            "emoji": "üìã",
            "patterns": ["—Å–æ—Å—Ç–∞–≤", "–∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç", "–¥–æ–±–∞–≤–∫", "–∫—Ä–∞—Å–∏—Ç–µ–ª—å", "—Ö–∏–º–∏—è"],
        },
    },
    "kitchen": {
        "not_heating": {
            "label": "–ù–µ –Ω–∞–≥—Ä–µ–≤–∞–µ—Ç / –Ω–µ –∫–∏–ø—è—Ç–∏—Ç",
            "emoji": "üî•",
            "patterns": ["–Ω–µ –∫–∏–ø—è—Ç", "–Ω–µ –≥—Ä–µ—Ç", "–Ω–µ –Ω–∞–≥—Ä–µ–≤", "—Ö–æ–ª–æ–¥–Ω", "–Ω–µ –≥–æ—Ä—è—á", "–¥–æ–ª–≥–æ –≥—Ä–µ—Ç", "–¥–æ–ª–≥–æ –∫–∏–ø—è—Ç"],
        },
        "leaking": {
            "label": "–ü—Ä–æ—Ç–µ–∫–∞–µ—Ç",
            "emoji": "üíß",
            "patterns": ["–ø—Ä–æ—Ç–µ", "—Ç–µ—á–µ—Ç", "—Ç–µ—á", "–∫–∞–ø–∞–µ—Ç", "–ø–æ–¥—Ç–µ–∫", "–ª—å—ë—Ç"],
        },
        "cable": {
            "label": "–ü—Ä–æ–±–ª–µ–º—ã —Å –∫–∞–±–µ–ª–µ–º / –ø–æ–¥—Å—Ç–∞–≤–∫–æ–π",
            "emoji": "üîå",
            "patterns": ["—à–Ω—É—Ä", "–∫–∞–±–µ–ª", "–ø—Ä–æ–≤–æ–¥", "–∑–∞—Ä—è–¥–∫", "usb", "–ø–æ–¥—Å—Ç–∞–≤–∫", "–∫–æ–Ω—Ç–∞–∫—Ç"],
        },
        "stopped_working": {
            "label": "–ü–µ—Ä–µ—Å—Ç–∞–ª —Ä–∞–±–æ—Ç–∞—Ç—å",
            "emoji": "‚õî",
            "patterns": ["–ø–µ—Ä–µ—Å—Ç–∞–ª", "–Ω–µ –≤–∫–ª—é—á", "—Å–≥–æ—Ä–µ–ª", "–≤—ã—à–µ–ª –∏–∑ —Å—Ç—Ä–æ—è", "–Ω–µ —Ä–∞–±–æ—Ç", "—Å–¥–æ—Ö"],
        },
        "noise": {
            "label": "–®—É–º–∏—Ç / –≥—É–¥–∏—Ç",
            "emoji": "üîä",
            "patterns": ["—à—É–º", "–≥—É–¥", "–≥—Ä–æ–º–∫", "—Ç–∏—Ö", "—Å–≤–∏—Å—Ç", "—Ç—Ä–µ—â"],
        },
        "smell_taste": {
            "label": "–ó–∞–ø–∞—Ö / –ø—Ä–∏–≤–∫—É—Å",
            "emoji": "üëÉ",
            "patterns": ["–∑–∞–ø–∞—Ö", "–ø–∞—Ö–Ω", "–ø—Ä–∏–≤–∫—É—Å", "–ø–ª–∞—Å—Ç–∏–∫", "–≤–æ–Ω—è–µ—Ç", "—Ö–∏–º–∏—è"],
        },
    },
    "home": {
        "fabric_quality": {
            "label": "–ö–∞—á–µ—Å—Ç–≤–æ —Ç–∫–∞–Ω–∏ / –º–∞—Ç–µ—Ä–∏–∞–ª–∞",
            "emoji": "üßµ",
            "patterns": ["—Ç–∫–∞–Ω—å", "–º–∞—Ç–µ—Ä–∏–∞–ª", "—Ç–æ–Ω–∫", "–ø—Ä–æ—Å–≤–µ—á", "–ª–∏–Ω—è–µ—Ç", "–∫–∞—Ç—ã—à", "—Ä–≤—ë—Ç"],
        },
        "size_mismatch": {
            "label": "–ù–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ä–∞–∑–º–µ—Ä—É",
            "emoji": "üìè",
            "patterns": ["—Ä–∞–∑–º–µ—Ä", "–º–∞–ª", "–≤–µ–ª–∏–∫", "—É–∑–∫", "–∫–æ—Ä–æ—Ç–∫", "–¥–ª–∏–Ω–Ω"],
        },
        "smell": {
            "label": "–ù–µ–ø—Ä–∏—è—Ç–Ω—ã–π –∑–∞–ø–∞—Ö",
            "emoji": "üëÉ",
            "patterns": ["–∑–∞–ø–∞—Ö", "–≤–æ–Ω—è–µ—Ç", "–ø–∞—Ö–Ω–µ—Ç", "—Ö–∏–º–∏—è", "–≤–æ–Ω—å"],
        },
        "color_fading": {
            "label": "–¶–≤–µ—Ç –≤—ã—Ü–≤–µ—Ç–∞–µ—Ç / –ª–∏–Ω—è–µ—Ç",
            "emoji": "üé®",
            "patterns": ["—Ü–≤–µ—Ç", "–ª–∏–Ω—è", "–≤—ã—Ü–≤–µ—Ç", "–ø–æ–ª–∏–Ω—è–ª", "–∫—Ä–∞—Å–∏—Ç", "—Å—Ç–∏—Ä–∫"],
        },
    },
    "beauty": {
        "allergy": {
            "label": "–ê–ª–ª–µ—Ä–≥–∏—è / —Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ",
            "emoji": "ü§ß",
            "patterns": ["–∞–ª–ª–µ—Ä–≥", "—Ä–∞–∑–¥—Ä–∞–∂", "–ø–æ–∫—Ä–∞—Å–Ω", "–∑—É–¥", "—á–µ—à–µ—Ç", "—Å—ã–ø—å", "–∂–∂—ë–Ω"],
        },
        "no_effect": {
            "label": "–ù–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∞",
            "emoji": "üòê",
            "patterns": ["–Ω–µ –ø–æ–º–æ–≥", "—ç—Ñ—Ñ–µ–∫—Ç", "–Ω–µ —Ä–∞–±–æ—Ç", "–±–µ—Å–ø–æ–ª–µ–∑–Ω", "–Ω–µ –∑–∞–º–µ—Ç", "–±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç"],
        },
        "texture": {
            "label": "–ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ü–∏—è / —Ç–µ–∫—Å—Ç—É—Ä–∞",
            "emoji": "üíß",
            "patterns": ["–∂–∏–¥–∫", "–≥—É—Å—Ç", "–∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ü", "—Ç–µ–∫—Å—Ç—É—Ä", "–ª–∏–ø–∫", "–∂–∏—Ä–Ω"],
        },
        "smell": {
            "label": "–ù–µ–ø—Ä–∏—è—Ç–Ω—ã–π –∑–∞–ø–∞—Ö",
            "emoji": "üëÉ",
            "patterns": ["–∑–∞–ø–∞—Ö", "–ø–∞—Ö–Ω", "–∞—Ä–æ–º–∞—Ç", "–≤–æ–Ω—è–µ—Ç", "–æ—Ç–¥—É—à–∫"],
        },
    },
    "toys": {
        "safety": {
            "label": "–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å (–º–µ–ª–∫–∏–µ –¥–µ—Ç–∞–ª–∏, –æ—Å—Ç—Ä—ã–µ –∫—Ä–∞—è)",
            "emoji": "‚ö†Ô∏è",
            "patterns": ["–æ—Å—Ç—Ä", "–º–µ–ª–∫", "–æ–ø–∞—Å–Ω", "–ø–æ—Ä–µ–∑", "—Ç–æ–∫—Å–∏—á–Ω", "–∫—Ä–∞—Å–∫"],
        },
        "durability": {
            "label": "–ë—ã—Å—Ç—Ä–æ –ª–æ–º–∞–µ—Ç—Å—è",
            "emoji": "üíî",
            "patterns": ["—Å–ª–æ–º–∞", "—Ä–∞–∑–≤–∞–ª", "—Ö–ª–∏–ø–∫", "–Ω–µ–ø—Ä–æ—á–Ω", "–æ—Ç–≤–∞–ª", "–æ—Ç–æ—Ä–≤–∞–ª"],
        },
        "not_as_pictured": {
            "label": "–ù–µ –∫–∞–∫ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ",
            "emoji": "üñºÔ∏è",
            "patterns": ["–Ω–µ –∫–∞–∫", "—Ñ–æ—Ç–æ", "–∫–∞—Ä—Ç–∏–Ω–∫", "–æ—Ç–ª–∏—á–∞–µ—Ç", "–æ–∂–∏–¥–∞–ª", "–æ–±–º–∞–Ω"],
        },
    },
    "auto": {
        "fitment": {
            "label": "–ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ —Ä–∞–∑–º–µ—Ä—É / –∫—Ä–µ–ø–ª–µ–Ω–∏—é",
            "emoji": "üîß",
            "patterns": ["–Ω–µ –ø–æ–¥—Ö–æ–¥", "–Ω–µ –ø–æ–¥–æ—à—ë–ª", "–∫—Ä–µ–ø–ª", "—Ä–∞–∑–º–µ—Ä", "–Ω–µ –≤–ª–µ–∑", "–Ω–µ –≤—Å—Ç–∞–ª"],
        },
        "material": {
            "label": "–ü–ª–æ—Ö–æ–π –º–∞—Ç–µ—Ä–∏–∞–ª",
            "emoji": "üß±",
            "patterns": ["–º–∞—Ç–µ—Ä–∏–∞–ª", "–ø–ª–∞—Å—Ç–∏–∫", "—Ö–ª–∏–ø–∫", "—Ç–æ–Ω–∫", "–¥–µ—à—ë–≤", "–∫–∏—Ç–∞–π"],
        },
    },
    "sports": {
        "durability": {
            "label": "–ë—ã—Å—Ç—Ä–æ –∏–∑–Ω–∞—à–∏–≤–∞–µ—Ç—Å—è",
            "emoji": "üíî",
            "patterns": ["–∏–∑–Ω–æ—Å", "–ø–æ—Ä–≤–∞–ª", "–ø—Ä–æ—Ç—ë—Ä", "—Ä–∞–∑–≤–∞–ª", "—Å–ª–æ–º–∞", "–ª–æ–ø–Ω—É–ª"],
        },
        "comfort": {
            "label": "–ù–µ—É–¥–æ–±–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å",
            "emoji": "üò£",
            "patterns": ["–Ω–µ—É–¥–æ–±–Ω", "–Ω–∞—Ç–∏—Ä–∞", "–¥–∞–≤–∏—Ç", "–∂–º—ë—Ç", "—Å–∫–æ–ª—å–∑", "–±–æ–ª—å–Ω"],
        },
        "smell": {
            "label": "–ó–∞–ø–∞—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–∞",
            "emoji": "üëÉ",
            "patterns": ["–∑–∞–ø–∞—Ö", "–≤–æ–Ω—è–µ—Ç", "–ø–∞—Ö–Ω–µ—Ç", "—Ö–∏–º–∏—è", "—Ä–µ–∑–∏–Ω"],
        },
    },
}

# –¢–µ–∫—É—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è (–º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –∫–∞–∫ –∞—Ä–≥—É–º–µ–Ω—Ç –∏–ª–∏ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
CURRENT_CATEGORY = "flashlight"

# –°–æ–±–∏—Ä–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å: —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ + –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—ã–µ
def get_reasons(category: str = None) -> dict:
    reasons = dict(UNIVERSAL_REASONS)
    if category and category in CATEGORY_PRESETS:
        reasons.update(CATEGORY_PRESETS[category])
    return reasons

REASONS = get_reasons(CURRENT_CATEGORY)

POSITIVE_HINTS = ("—Ö–æ—Ä–æ—à", "–æ—Ç–ª–∏—á", "–Ω—Ä–∞–≤", "–∫–ª–∞—Å—Å", "—Ä–µ–∫–æ–º–µ–Ω–¥", "—Å—É–ø–µ—Ä")


def detect_category(product_name: str = None, feedbacks: list = None) -> str:
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ç–æ–≤–∞—Ä–∞ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∏–ª–∏ —Ç–µ–∫—Å—Ç–∞–º –æ—Ç–∑—ã–≤–æ–≤."""
    # 1. –ü—Ä–æ–±—É–µ–º –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é —Ç–æ–≤–∞—Ä–∞
    if product_name:
        name_lower = product_name.lower()
        for category, keywords in CATEGORY_KEYWORDS.items():
            for kw in keywords:
                if kw in name_lower:
                    return category

    # 2. –ü—Ä–æ–±—É–µ–º –ø–æ —Ç–µ–∫—Å—Ç–∞–º –æ—Ç–∑—ã–≤–æ–≤ (–ø–µ—Ä–≤—ã–µ 20)
    if feedbacks:
        category_scores = {cat: 0 for cat in CATEGORY_KEYWORDS}
        for fb in feedbacks[:20]:
            text = " ".join([
                fb.get("fb_text") or "",
                fb.get("advantages") or "",
                fb.get("disadvantages") or "",
            ]).lower()
            for category, keywords in CATEGORY_KEYWORDS.items():
                for kw in keywords:
                    if kw in text:
                        category_scores[category] += 1
                        break
        # –í—ã–±–∏—Ä–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —Å—á—ë—Ç–æ–º
        best = max(category_scores.items(), key=lambda x: x[1])
        if best[1] >= 2:  # –º–∏–Ω–∏–º—É–º 2 —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            return best[0]

    return "general"  # default fallback ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è


def parse_date(value: str):
    if not value:
        return None
    try:
        return datetime.fromisoformat(value.replace("Z", "+00:00"))
    except Exception:
        return None


def normalize_text(text: str) -> str:
    text = text.lower().strip()
    text = re.sub(r"[^a-z–∞-—è0-9\s-]", " ", text)
    text = re.sub(r"\s+", " ", text)
    return text


def is_color_variant(label: str) -> bool:
    t = normalize_text(label)
    if not t:
        return False
    if any(c in t for c in COLOR_WORDS):
        return True
    return False


def normalize_variant(raw: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç: '–ß–µ—Ä–Ω—ã–π ¬∑ 0.45 –ª' -> '—á–µ—Ä–Ω—ã–π', '–±–µ–ª—ã–π –∏–Ω–µ–π' -> '–±–µ–ª—ã–π'."""
    v = raw.lower().strip()
    # –£–±—Ä–∞—Ç—å —Ä–∞–∑–º–µ—Ä/–æ–±—ä—ë–º –ø–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è: "–ß–µ—Ä–Ω—ã–π ¬∑ 0.45 –ª" -> "—á–µ—Ä–Ω—ã–π"
    v = re.sub(r'[¬∑\-/]\s*\d+.*$', '', v).strip()
    # –£–±—Ä–∞—Ç—å —á–∏—Å–ª–∞ —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏: "—á–µ—Ä–Ω—ã–π 0.45 –ª" -> "—á–µ—Ä–Ω—ã–π"
    v = re.sub(r'\s+\d+[\.,]?\d*\s*(–ª|–º–ª|—à—Ç|–º|–º–º|—Å–º|–∫–≥|–≥—Ä)\b.*$', '', v).strip()
    # –£–±—Ä–∞—Ç—å –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã —Ü–≤–µ—Ç–∞: "–±–µ–ª—ã–π –∏–Ω–µ–π" -> "–±–µ–ª—ã–π", "—Å–∏–Ω–∏–π –º–µ—Ç–∞–ª–ª–∏–∫" -> "—Å–∏–Ω–∏–π"
    v = re.sub(r'\s+(–∏–Ω–µ–π|–º–µ—Ç–∞–ª–ª–∏–∫|–ø–µ—Ä–ª–∞–º—É—Ç—Ä|–º–∞—Ç–æ–≤—ã–π|–≥–ª—è–Ω—Ü–µ–≤—ã–π|–Ω–∞—Å—ã—â–µ–Ω–Ω—ã–π)$', '', v).strip()
    return v


def load_payload(path: str):
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    if isinstance(data, list) and data:
        return data[0]
    return data


def get_actions(category: str, target_variant: str, reason_rows: list = None) -> list:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–∏—á–∏–Ω."""
    actions = []

    # 1. –í—Å–µ–≥–¥–∞: –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–∞—Ä—Ç–∏–∏
    if target_variant and target_variant != "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä":
        actions.append(f"–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–∞—Ä—Ç–∏–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞ ¬´{target_variant}¬ª –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π")
    else:
        actions.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–∞—Ä—Ç–∏–∏ —Ç–æ–≤–∞—Ä–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π")

    # 2. –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ top –ø—Ä–∏—á–∏–Ω—ã
    if reason_rows:
        top_reason = reason_rows[0].get("label", "").lower()
        if any(w in top_reason for w in ["–Ω–∞–≥—Ä–µ–≤", "–∫–∏–ø—è—Ç"]):
            actions.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–≥—Ä–µ–≤–∞—Ç–µ–ª—å–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç –∏ —Ç–µ—Ä–º–æ—Å—Ç–∞—Ç —É –ø–∞—Ä—Ç–∏–∏")
        elif any(w in top_reason for w in ["–ø—Ä–æ—Ç–µ–∫", "—Ç–µ—á"]):
            actions.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≥–µ—Ä–º–µ—Ç–∏—á–Ω–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ —Å–±–æ—Ä–∫–∏")
        elif any(w in top_reason for w in ["–∫–∞–±–µ–ª", "—à–Ω—É—Ä", "–ø–æ–¥—Å—Ç–∞–≤–∫", "–∫–æ–Ω—Ç–∞–∫—Ç"]):
            actions.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–º–ø–ª–µ–∫—Ç–Ω–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ –∫–∞–±–µ–ª—è/–ø–æ–¥—Å—Ç–∞–≤–∫–∏")
        elif any(w in top_reason for w in ["–ø–µ—Ä–µ—Å—Ç–∞–ª", "–Ω–µ —Ä–∞–±–æ—Ç", "–Ω–µ –≤–∫–ª—é—á"]):
            actions.append("–°–≤—è–∑–∞—Ç—å—Å—è —Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–µ–º ‚Äî –º–∞—Å—Å–æ–≤—ã–π –¥–µ—Ñ–µ–∫—Ç –ø–∞—Ä—Ç–∏–∏")
        elif any(w in top_reason for w in ["—à—É–º", "–≥—É–¥", "–≥—Ä–æ–º–∫"]):
            actions.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —à—É–º–æ–∏–∑–æ–ª—è—Ü–∏—é –∏ –∫–∞—á–µ—Å—Ç–≤–æ —Å–±–æ—Ä–∫–∏")
        elif any(w in top_reason for w in ["–≤–æ–¥", "–≤–ª–∞–≥", "–≥–µ—Ä–º–µ—Ç–∏—á–Ω"]):
            actions.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≥–µ—Ä–º–µ—Ç–∏—á–Ω–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ —Å–±–æ—Ä–∫–∏")
        elif any(w in top_reason for w in ["—è—Ä–∫–æ—Å—Ç—å", "—Å–≤–µ—Ç", "—Ç—É—Å–∫–ª"]):
            actions.append("–°–≤–µ—Ä–∏—Ç—å –∑–∞—è–≤–ª–µ–Ω–Ω—É—é —è—Ä–∫–æ—Å—Ç—å —Å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–π")
        elif any(w in top_reason for w in ["—Ä–∞–∑–º–µ—Ä", "–º–∞–ª–æ–º–µ—Ä", "–±–æ–ª—å—à–µ–º–µ—Ä"]):
            actions.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ–π —Å–µ—Ç–∫–∏")
        elif any(w in top_reason for w in ["–±–∞—Ç–∞—Ä–µ", "–∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä", "–∑–∞—Ä—è–¥"]):
            actions.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —ë–º–∫–æ—Å—Ç—å –±–∞—Ç–∞—Ä–µ–∏ –∏ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã")
        elif any(w in top_reason for w in ["–∑–∞–ø–∞—Ö", "–ø–∞—Ö–Ω", "–ø—Ä–∏–≤–∫—É—Å"]):
            actions.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ —É—Å–ª–æ–≤–∏—è —Ö—Ä–∞–Ω–µ–Ω–∏—è")
        elif any(w in top_reason for w in ["—Ü–≤–µ—Ç", "–æ—Ç–ª–∏—á–∞", "–ª–∏–Ω—è", "–≤—ã—Ü–≤–µ—Ç"]):
            actions.append("–°–≤–µ—Ä–∏—Ç—å —Ñ–æ—Ç–æ —Ç–æ–≤–∞—Ä–∞ —Å —Ä–µ–∞–ª—å–Ω—ã–º —Ü–≤–µ—Ç–æ–º")
        elif any(w in top_reason for w in ["–±—Ä–∞–∫", "–¥–µ—Ñ–µ–∫—Ç", "—Å–ª–æ–º–∞–ª"]):
            actions.append("–°–≤—è–∑–∞—Ç—å—Å—è —Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–µ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –ø–∞—Ä—Ç–∏–∏")
        elif any(w in top_reason for w in ["–Ω–µ —Ç–æ—Ç", "–ø—É—Ç–∞—é—Ç", "–ø–µ—Ä–µ—Å–æ—Ä—Ç"]):
            actions.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏—Å—Ç–∏–∫—É –∏ –∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏—é –Ω–∞ —Å–∫–ª–∞–¥–µ")
        elif any(w in top_reason for w in ["–∞–ª–ª–µ—Ä–≥", "—Ä–∞–∑–¥—Ä–∞–∂"]):
            actions.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã –∏ —Å–æ—Å—Ç–∞–≤ –ø—Ä–æ–¥—É–∫—Ç–∞")
        elif any(w in top_reason for w in ["–ª–æ–º–∞–µ—Ç", "—Ä–∞–∑–≤–∞–ª", "—Ö–ª–∏–ø–∫", "–Ω–µ–ø—Ä–æ—á–Ω"]):
            actions.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –∏ —Å–±–æ—Ä–∫–∏")
        else:
            actions.append("–°–≤–µ—Ä–∏—Ç—å –∑–∞—è–≤–ª–µ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏")

    # 3. –í—Å–µ–≥–¥–∞: –æ–±–Ω–æ–≤–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ
    actions.append("–û–±–Ω–æ–≤–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ —Å —É—á—ë—Ç–æ–º –≤—ã—è–≤–ª–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º")

    # 4. –í—Å–µ–≥–¥–∞: –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –æ—Ç–∑—ã–≤—ã
    actions.append("–û—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –æ—Ç–∑—ã–≤—ã –ø–æ —à–∞–±–ª–æ–Ω—É (–Ω–∏–∂–µ)")

    return actions


def get_reply_template(category: str, main_reason: str) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —à–∞–±–ª–æ–Ω –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–ª–∞–≤–Ω–æ–π –ø—Ä–∏—á–∏–Ω—ã –Ω–µ–≥–∞—Ç–∏–≤–∞."""
    reason_lower = main_reason.lower() if main_reason else ""

    if any(w in reason_lower for w in ["–Ω–∞–≥—Ä–µ–≤", "–∫–∏–ø—è—Ç"]):
        return "–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–∑—ã–≤. –ü—Ä–∏–Ω–æ—Å–∏–º –∏–∑–≤–∏–Ω–µ–Ω–∏—è! –ú—ã —É–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–≥—Ä–µ–≤–∞—Ç–µ–ª—å–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç —É –¥–∞–Ω–Ω–æ–π –ø–∞—Ä—Ç–∏–∏. –ù–∞–ø–∏—à–∏—Ç–µ –Ω–∞–º ‚Äî –ø–æ–º–æ–∂–µ–º —Å –∑–∞–º–µ–Ω–æ–π."
    elif any(w in reason_lower for w in ["–ø—Ä–æ—Ç–µ–∫", "—Ç–µ—á"]):
        return "–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–∑—ã–≤. –ù–∞–º –≤–∞–∂–Ω–æ –≤–∞—à–µ –∑–∞–º–µ—á–∞–Ω–∏–µ. –ú—ã –ø—Ä–æ–≤–µ—Ä—è–µ–º –≥–µ—Ä–º–µ—Ç–∏—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω–æ–π –ø–∞—Ä—Ç–∏–∏. –ù–∞–ø–∏—à–∏—Ç–µ –Ω–∞–º –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞."
    elif any(w in reason_lower for w in ["–∫–∞–±–µ–ª", "—à–Ω—É—Ä", "–ø–æ–¥—Å—Ç–∞–≤–∫"]):
        return "–ë–ª–∞–≥–æ–¥–∞—Ä–∏–º –∑–∞ –æ—Ç–∑—ã–≤! –ü—Ä–∏–Ω–æ—Å–∏–º –∏–∑–≤–∏–Ω–µ–Ω–∏—è –∑–∞ –Ω–µ—É–¥–æ–±—Å—Ç–≤–∞. –ú—ã –ø—Ä–æ–≤–µ—Ä–∏–º –∫–æ–º–ø–ª–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω–æ–π –ø–∞—Ä—Ç–∏–∏. –ù–∞–ø–∏—à–∏—Ç–µ –Ω–∞–º ‚Äî –ø–æ–º–æ–∂–µ–º —Ä–µ—à–∏—Ç—å –≤–æ–ø—Ä–æ—Å."
    elif any(w in reason_lower for w in ["–ø–µ—Ä–µ—Å—Ç–∞–ª", "–Ω–µ —Ä–∞–±–æ—Ç", "–Ω–µ –≤–∫–ª—é—á"]):
        return "–ë–ª–∞–≥–æ–¥–∞—Ä–∏–º –∑–∞ –æ—Ç–∑—ã–≤! –ü—Ä–∏–Ω–æ—Å–∏–º –∏–∑–≤–∏–Ω–µ–Ω–∏—è –∑–∞ –¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –Ω–µ—É–¥–æ–±—Å—Ç–≤–∞. –ú—ã –ø–µ—Ä–µ–¥–∞–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—é –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∞—Ä—Ç–∏–∏. –ù–∞–ø–∏—à–∏—Ç–µ –Ω–∞–º ‚Äî –ø–æ–º–æ–∂–µ–º —Å –≤–æ–∑–≤—Ä–∞—Ç–æ–º."
    elif any(w in reason_lower for w in ["—à—É–º", "–≥—É–¥"]):
        return "–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–∑—ã–≤. –ú—ã –ø—Ä–æ–≤–µ—Ä–∏–º –∫–∞—á–µ—Å—Ç–≤–æ —Å–±–æ—Ä–∫–∏ –¥–∞–Ω–Ω–æ–π –ø–∞—Ä—Ç–∏–∏. –ù–∞–ø–∏—à–∏—Ç–µ –Ω–∞–º ‚Äî –ø–æ–º–æ–∂–µ–º —Ä–µ—à–∏—Ç—å –≤–æ–ø—Ä–æ—Å."
    elif any(w in reason_lower for w in ["–≤–æ–¥", "–≤–ª–∞–≥", "–≥–µ—Ä–º–µ—Ç–∏—á–Ω"]):
        return "–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–∑—ã–≤. –ù–∞–º –≤–∞–∂–Ω–æ –≤–∞—à–µ –∑–∞–º–µ—á–∞–Ω–∏–µ. –ú—ã —É–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Å–±–æ—Ä–∫–∏ –∏ –≥–µ—Ä–º–µ—Ç–∏—á–Ω–æ—Å—Ç—å –ø–æ –¥–∞–Ω–Ω–æ–π –ø–∞—Ä—Ç–∏–∏."
    elif any(w in reason_lower for w in ["–±—Ä–∞–∫", "–¥–µ—Ñ–µ–∫—Ç", "—Å–ª–æ–º–∞–ª"]):
        return "–ë–ª–∞–≥–æ–¥–∞—Ä–∏–º –∑–∞ –æ—Ç–∑—ã–≤! –ü—Ä–∏–Ω–æ—Å–∏–º –∏–∑–≤–∏–Ω–µ–Ω–∏—è –∑–∞ –¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –Ω–µ—É–¥–æ–±—Å—Ç–≤–∞. –ú—ã –ø–µ—Ä–µ–¥–∞–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–µ—Ñ–µ–∫—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—é –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∞—Ä—Ç–∏–∏."
    elif any(w in reason_lower for w in ["—Ä–∞–∑–º–µ—Ä", "–º–∞–ª–æ–º–µ—Ä", "–±–æ–ª—å—à–µ–º–µ—Ä"]):
        return "–ë–ª–∞–≥–æ–¥–∞—Ä–∏–º –∑–∞ –æ—Ç–∑—ã–≤! –ú—ã –æ–±–Ω–æ–≤–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑–º–µ—Ä–∞—Ö –≤ –∫–∞—Ä—Ç–æ—á–∫–µ —Ç–æ–≤–∞—Ä–∞, —á—Ç–æ–±—ã –¥—Ä—É–≥–∏–º –ø–æ–∫—É–ø–∞—Ç–µ–ª—è–º –±—ã–ª–æ –ø—Ä–æ—â–µ –≤—ã–±—Ä–∞—Ç—å."
    elif any(w in reason_lower for w in ["–Ω–µ —Ç–æ—Ç", "–ø—É—Ç–∞—é—Ç", "–ø–µ—Ä–µ—Å–æ—Ä—Ç"]):
        return "–ë–ª–∞–≥–æ–¥–∞—Ä–∏–º –∑–∞ –æ—Ç–∑—ã–≤! –ü—Ä–∏–Ω–æ—Å–∏–º –∏–∑–≤–∏–Ω–µ–Ω–∏—è –∑–∞ –ø—É—Ç–∞–Ω–∏—Ü—É. –≠—Ç–æ –æ—à–∏–±–∫–∞ –∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏–∏ –Ω–∞ —Å–∫–ª–∞–¥–µ. –ù–∞–ø–∏—à–∏—Ç–µ –Ω–∞–º ‚Äî –ø–æ–º–æ–∂–µ–º —Ä–µ—à–∏—Ç—å –≤–æ–ø—Ä–æ—Å."
    elif any(w in reason_lower for w in ["–∑–∞–ø–∞—Ö", "–ø–∞—Ö–Ω", "–ø—Ä–∏–≤–∫—É—Å"]):
        return "–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–∑—ã–≤. –ú—ã –ø—Ä–æ–≤–µ—Ä–∏–º —É—Å–ª–æ–≤–∏—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–∞–Ω–Ω–æ–π –ø–∞—Ä—Ç–∏–∏."
    elif any(w in reason_lower for w in ["–±–∞—Ç–∞—Ä–µ", "–∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä", "–∑–∞—Ä—è–¥"]):
        return "–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–∑—ã–≤. –ú—ã –ø—Ä–æ–≤–µ—Ä–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã –∏ –æ–±–Ω–æ–≤–∏–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Ç–æ–≤–∞—Ä–∞."
    elif any(w in reason_lower for w in ["–∞–ª–ª–µ—Ä–≥", "—Ä–∞–∑–¥—Ä–∞–∂"]):
        return "–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–∑—ã–≤. –ú—ã –ø—Ä–æ–≤–µ—Ä–∏–º —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã –∏ —Å–æ—Å—Ç–∞–≤ –¥–∞–Ω–Ω–æ–π –ø–∞—Ä—Ç–∏–∏. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –≤—Ä–∞—á—É –ø—Ä–∏ —Å–∏–ª—å–Ω–æ–π —Ä–µ–∞–∫—Ü–∏–∏."
    else:
        return "–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–∑—ã–≤. –ù–∞–º –≤–∞–∂–Ω–æ –≤–∞—à–µ –∑–∞–º–µ—á–∞–Ω–∏–µ. –ú—ã —É–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ —É—Ç–æ—á–Ω–∏–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Ç–æ–≤–∞—Ä–∞."


def classify_reasons(text: str, is_disadvantage: bool = False) -> list:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –ø–æ –ø—Ä–∏—á–∏–Ω–∞–º (multi-label).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–∏—á–∏–Ω.
    """
    t = normalize_text(text)
    if not t:
        return []
    # –î–ª—è fb_text —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ–∑–∏—Ç–∏–≤, –¥–ª—è disadvantages ‚Äî –Ω–µ—Ç
    if not is_disadvantage and any(h in t for h in POSITIVE_HINTS):
        return []

    found = []
    for key, meta in REASONS.items():
        for p in meta["patterns"]:
            if p in t:
                found.append(key)
                break  # –û–¥–∏–Ω –ø–∞—Ç—Ç–µ—Ä–Ω –Ω–∞ –ø—Ä–∏—á–∏–Ω—É –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ

    return found if found else ["other"]


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# LLM fallback wrappers
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _get_actions_with_fallback(use_llm: bool, category: str, target_variant: str, reason_rows: list) -> list:
    """Try LLM actions, fall back to rule-based."""
    if use_llm and reason_rows:
        try:
            result = llm_get_actions(category, target_variant, reason_rows)
            if result:
                print(f"LLM get_actions: OK ({len(result)} actions)")
                return result
            print("LLM get_actions: returned None, fallback")
        except Exception as e:
            print(f"LLM get_actions: error {e}, fallback")
    return get_actions(category, target_variant, reason_rows)


def _get_reply_with_fallback(use_llm: bool, category: str, main_reason: str, product_name: str, target_variant: str) -> str:
    """Try LLM reply, fall back to rule-based."""
    if use_llm and main_reason:
        try:
            result = llm_get_reply_template(category, main_reason, product_name, target_variant)
            if result:
                print(f"LLM get_reply: OK")
                return result
            print("LLM get_reply: returned None, fallback")
        except Exception as e:
            print(f"LLM get_reply: error {e}, fallback")
    return get_reply_template(category, main_reason)


def main():
    if len(sys.argv) < 3:
        print("Usage: wbcon-task-to-card-v2.py <task-json> <output-json> [variant_name] [category]")
        print("Categories: flashlight, clothing, electronics, pet_food (auto-detected if not specified)")
        sys.exit(1)

    src_path = sys.argv[1]
    out_path = sys.argv[2]
    target_variant = sys.argv[3] if len(sys.argv) > 3 else None
    category_arg = sys.argv[4] if len(sys.argv) > 4 else None

    payload = load_payload(src_path)

    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –∞–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç–∞
    feedbacks = payload.get("feedbacks", []) if isinstance(payload, dict) else []
    product_name = payload.get("product_name") or ""
    if not product_name and feedbacks:
        product_name = feedbacks[0].get("product_name") or feedbacks[0].get("name") or ""

    # Fetch WB card description (public API, no auth)
    nm_id = None
    if feedbacks:
        nm_id = feedbacks[0].get("article")
    wb_card = fetch_wb_card_info(nm_id) if nm_id else None

    if wb_card:
        if not product_name:
            product_name = wb_card["imt_name"]

    # Fetch questions from WBCON
    questions = []
    wbcon_email = os.getenv("WBCON_EMAIL", "")
    wbcon_pass = os.getenv("WBCON_PASS", "")
    if nm_id and wbcon_email and wbcon_pass:
        questions = fetch_wbcon_questions(int(nm_id), wbcon_email, wbcon_pass)

    # –ê–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞
    category = category_arg or detect_category(product_name, feedbacks)
    print(f"Category: {category} (auto-detected: {category_arg is None})")

    # LLM mode
    use_llm = os.getenv("USE_LLM", "1") == "1" and LLM_AVAILABLE
    print(f"LLM mode: {'enabled' if use_llm else 'disabled'}")

    # –ü–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º REASONS –ø–æ–¥ –≤—ã–±—Ä–∞–Ω–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
    global REASONS
    REASONS = get_reasons(category)
    feedbacks = payload.get("feedbacks", []) if isinstance(payload, dict) else []

    # Deduplicate feedbacks by ID
    seen_ids = set()
    unique_feedbacks = []
    for fb in feedbacks:
        fb_id = fb.get("id") or fb.get("fb_id")
        if fb_id and fb_id in seen_ids:
            continue
        if fb_id:
            seen_ids.add(fb_id)
        unique_feedbacks.append(fb)
    if len(unique_feedbacks) < len(feedbacks):
        print(f"Dedup: {len(feedbacks)} -> {len(unique_feedbacks)} feedbacks")
    feedbacks = unique_feedbacks

    # Filter feedbacks to last 12 months (366 days to include boundary dates)
    now_utc = datetime.now(timezone.utc)
    cutoff_12months = now_utc - timedelta(days=366)
    filtered_feedbacks = []
    for fb in feedbacks:
        created_str = fb.get("created_at") or fb.get("fb_created_at") or ""
        if not created_str:
            continue
        try:
            # Parse ISO date: "2025-02-07T12:34:56Z" or "2025-02-07 12:34:56"
            created_dt = datetime.fromisoformat(created_str.replace('Z', '+00:00'))
            if created_dt.tzinfo is None:
                created_dt = created_dt.replace(tzinfo=timezone.utc)
            if created_dt >= cutoff_12months:
                filtered_feedbacks.append(fb)
        except (ValueError, AttributeError):
            # If date parse fails, include (safer to include than exclude)
            filtered_feedbacks.append(fb)
    if len(filtered_feedbacks) < len(feedbacks):
        print(f"12-month filter: {len(feedbacks)} -> {len(filtered_feedbacks)} feedbacks")
    feedbacks = filtered_feedbacks

    # Build article -> display_name mapping
    # Group by article, use article as variant key (reliable), color as display name
    # WBCON may return different color names for same article (renamed over time)
    # so we just strip size/volume suffixes but keep color modifiers
    now = datetime.now(timezone.utc)
    cutoff = now - timedelta(days=WINDOW_DAYS)
    cutoff_prev = now - timedelta(days=WINDOW_DAYS * 2)

    has_multiple_articles = len(set(f.get("article", "") for f in feedbacks if f.get("article"))) > 1
    # Track colors per article ‚Äî prefer recent names (WBCON may rename variants)
    article_colors_recent = defaultdict(lambda: Counter())  # last 30 days
    article_colors_all = defaultdict(lambda: Counter())
    for fb in feedbacks:
        art = fb.get("article", "")
        color = (fb.get("color") or "").strip()
        if not art or not color:
            continue
        # Normalize: "—Å–µ—Ä—ã–π, –∑–µ–ª–µ–Ω—ã–π, —Ö–∞–∫–∏" -> "—Å–µ—Ä—ã–π", "–ë–µ–ª—ã–π ¬∑ 0.45 –ª" -> "–±–µ–ª—ã–π"
        c = color.lower().strip()
        # Multi-color: take first color only
        if ", " in c:
            c = c.split(", ")[0].strip()
        c = re.sub(r'[¬∑\-/]\s*\d+.*$', '', c).strip()
        c = re.sub(r'\s+\d+[\.,]?\d*\s*(–ª|–º–ª|—à—Ç|–º|–º–º|—Å–º|–∫–≥|–≥—Ä)\b.*$', '', c).strip()
        article_colors_all[art][c] += 1
        dt = parse_date(fb.get("fb_created_at") or "")
        if dt and dt >= cutoff:
            article_colors_recent[art][c] += 1

    article_display = {}
    # First pass: get color for each article (prefer real colors over "1 —à—Ç." labels)
    art_color_map = {}
    for art in article_colors_all:
        # Try recent first, fall back to all-time, but always prefer window with real colors
        recent = article_colors_recent.get(art)
        all_colors = article_colors_all[art]
        if not all_colors:
            art_color_map[art] = "?"
            continue
        recent_real = {c: n for c, n in (recent or {}).items() if c and is_color_variant(c)}
        all_real = {c: n for c, n in all_colors.items() if c and is_color_variant(c)}
        if recent_real:
            real_colors = recent_real
        elif all_real:
            real_colors = all_real
        else:
            art_color_map[art] = f"–∞—Ä—Ç. ...{art[-4:]}" if len(art) >= 4 else f"–∞—Ä—Ç. {art}"
            continue
        best = sorted(real_colors.items(), key=lambda x: (-x[1], -len(x[0])))[0][0]
        art_color_map[art] = best

    # Count how many articles share the same color name
    color_usage = Counter(art_color_map.values())

    # Second pass: if color is unique ‚Äî just use color; if duplicate ‚Äî add article number
    color_seen = Counter()
    for art in sorted(art_color_map.keys()):
        color_name = art_color_map[art]
        if color_usage[color_name] > 1:
            color_seen[color_name] += 1
            article_display[art] = f"{color_name} #{color_seen[color_name]}"
        else:
            article_display[art] = color_name

    if has_multiple_articles:
        print(f"Article->variant mapping: {dict(article_display)}")
    else:
        print(f"Single article, using color field for variants")

    # Stats by variant
    variant_stats = defaultdict(lambda: {"count": 0, "sum": 0.0})
    variant_recent = defaultdict(lambda: {"count": 0, "sum": 0.0})
    variant_prev = defaultdict(lambda: {"count": 0, "sum": 0.0})  # –ü—Ä–µ–¥—ã–¥—É—â–∏–π –ø–µ—Ä–∏–æ–¥
    variant_reason_counts = defaultdict(lambda: Counter())
    variant_reason_recent = defaultdict(lambda: Counter())

    # LLM: –∫–æ–ª–ª–µ–∫—Ç–æ—Ä –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –±–∞—Ç—á-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    negative_texts_for_llm = []  # [{"variant": str, "text": str}]
    # Review samples for display in card (all negative reviews, not just LLM mode)
    negative_review_samples = []  # [{"variant": str, "text": str, "rating": int, "date": str}]

    for f in feedbacks:
        # Determine variant: use article mapping if multiple articles, else use color
        if has_multiple_articles:
            art = f.get("article", "")
            variant = article_display.get(art, art) if art else "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä"
        else:
            variant_raw = f.get("color") or f.get("size") or "–û—Å—Ç–∞–ª—å–Ω—ã–µ"
            variant = variant_raw.strip()
            if is_color_variant(variant):
                variant = normalize_variant(variant)
            else:
                variant = "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä"
        rating_val = float(f.get("valuation") or 0)
        dt = parse_date(f.get("fb_created_at") or "")

        variant_stats[variant]["count"] += 1
        variant_stats[variant]["sum"] += rating_val

        if dt and dt >= cutoff:
            variant_recent[variant]["count"] += 1
            variant_recent[variant]["sum"] += rating_val
        elif dt and dt >= cutoff_prev:
            # –ü—Ä–µ–¥—ã–¥—É—â–∏–π –ø–µ—Ä–∏–æ–¥ (30-60 –¥–Ω–µ–π –Ω–∞–∑–∞–¥)
            variant_prev[variant]["count"] += 1
            variant_prev[variant]["sum"] += rating_val

        # Reasons: use disadvantages + advantages (–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç) + fb_text
        disadvantages = f.get("disadvantages") or ""
        advantages = f.get("advantages") or ""
        fb_text = f.get("fb_text") or ""

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–∏—á–∏–Ω—ã (multi-label)
        reasons_found = set()

        # 1. disadvantages ‚Äî —Ç–æ—á–Ω–æ –Ω–µ–≥–∞—Ç–∏–≤
        if disadvantages:
            reasons_found.update(classify_reasons(disadvantages, is_disadvantage=True))

        # 2. advantages —Å –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º (–ª—é–¥–∏ –ø–∏—à—É—Ç –∂–∞–ª–æ–±—ã –≤ advantages)
        if advantages and rating_val <= 3:
            reasons_found.update(classify_reasons(advantages, is_disadvantage=True))

        # 3. fb_text ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –¥—Ä—É–≥–∏—Ö –ø–æ–ª—è—Ö
        if not reasons_found and fb_text:
            reasons_found.update(classify_reasons(fb_text, is_disadvantage=False))

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã
        for reason in reasons_found:
            variant_reason_counts[variant][reason] += 1
            if dt and dt >= cutoff:
                variant_reason_recent[variant][reason] += 1

        # Collect negative review samples for display + LLM
        if rating_val <= 3:
            # Best text for display: disadvantages > fb_text > advantages
            display_text = disadvantages or fb_text or advantages or ""
            if display_text.strip():
                negative_review_samples.append({
                    "variant": variant,
                    "text": display_text.strip()[:200],
                    "rating": int(rating_val),
                    "date": (f.get("fb_created_at") or "")[:10],
                })

            # LLM: full combined text for classification
            if use_llm:
                combined_parts = []
                if disadvantages:
                    combined_parts.append(disadvantages)
                if advantages:
                    combined_parts.append(advantages)
                if fb_text:
                    combined_parts.append(fb_text)
                combined_text = " ".join(combined_parts).strip()
                if combined_text:
                    negative_texts_for_llm.append({
                        "variant": variant,
                        "text": combined_text,
                    })

    # Overall rating
    total = payload.get("feedback_count", len(feedbacks)) or 0
    rating = payload.get("rating") or 0
    if not rating:
        counts = {
            5: payload.get("five_valuation_distr", 0),
            4: payload.get("four_valuation_distr", 0),
            3: payload.get("three_valuation_distr", 0),
            2: payload.get("two_valuation_distr", 0),
            1: payload.get("one_valuation_distr", 0),
        }
        dist_total = sum(counts.values()) or total or 1
        rating = round(sum(k * v for k, v in counts.items()) / dist_total, 2)

    # Variant ratings
    def avg(stats):
        return round(stats["sum"] / stats["count"], 2) if stats["count"] else 0

    valid_colors = [v for v in variant_stats.keys() if v != "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä"]

    # –ê–≤—Ç–æ–≤—ã–±–æ—Ä –≤–∞—Ä–∏–∞–Ω—Ç–∞: —Ö—É–¥—à–∏–π –ø–æ —Ä–µ–π—Ç–∏–Ω–≥—É (–µ—Å–ª–∏ —Å—Ç–∞—Ç. –∑–Ω–∞—á–∏–º–æ)
    if target_variant is None or target_variant not in variant_stats:
        if valid_colors:
            candidates = [v for v in valid_colors if variant_stats[v]["count"] >= MIN_REVIEWS_FOR_SIGNAL]
            if candidates:
                # Average of all candidates (weighted)
                all_sum = sum(variant_stats[v]["sum"] for v in candidates)
                all_cnt = sum(variant_stats[v]["count"] for v in candidates)
                overall_avg = all_sum / all_cnt if all_cnt else 0
                # Find worst variant that's significantly below others
                worst = min(candidates, key=lambda k: avg(variant_stats[k]))
                worst_avg = avg(variant_stats[worst])
                others = [v for v in candidates if v != worst]
                if others:
                    others_sum = sum(variant_stats[v]["sum"] for v in others)
                    others_cnt = sum(variant_stats[v]["count"] for v in others)
                    others_avg = others_sum / others_cnt if others_cnt else 0
                else:
                    others_avg = overall_avg
                gap = round(others_avg - worst_avg, 1)
                if gap >= MIN_GAP_FOR_SIGNAL:
                    target_variant = worst
                else:
                    # No significant gap ‚Äî pick variant with most reviews for general report
                    target_variant = max(candidates, key=lambda k: variant_stats[k]["count"])
            else:
                target_variant = max(valid_colors, key=lambda k: variant_stats[k]["count"])
        else:
            target_variant = "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä"
    elif target_variant not in valid_colors and valid_colors:
        target_variant = max(valid_colors, key=lambda k: variant_stats[k]["count"])

    target_stats = variant_stats.get(target_variant or "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä", {"count": 0, "sum": 0.0})
    target_avg = avg(target_stats)

    # –¢—Ä–µ–Ω–¥: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º
    # First try 30-day windows; if insufficient data ‚Äî split all data in half by date
    target_recent = variant_recent.get(target_variant or "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä", {"count": 0, "sum": 0.0})
    target_prev = variant_prev.get(target_variant or "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä", {"count": 0, "sum": 0.0})

    trend = None
    trend_delta = 0
    MIN_TREND_REVIEWS = 3
    if target_recent["count"] >= MIN_TREND_REVIEWS and target_prev["count"] >= MIN_TREND_REVIEWS:
        trend_delta = round(avg(target_recent) - avg(target_prev), 2)
    else:
        # Fallback: split target variant's feedbacks into older half / newer half
        target_dates_ratings = []
        for fb in feedbacks:
            if has_multiple_articles:
                art = fb.get("article", "")
                v = article_display.get(art, art) if art else "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä"
            else:
                v_raw = fb.get("color") or fb.get("size") or "–û—Å—Ç–∞–ª—å–Ω—ã–µ"
                v = normalize_variant(v_raw.strip()) if is_color_variant(v_raw.strip()) else "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä"
            if v != (target_variant or "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä"):
                continue
            dt = parse_date(fb.get("fb_created_at") or "")
            r = float(fb.get("valuation") or 0)
            if dt and r > 0:
                target_dates_ratings.append((dt, r))
        target_dates_ratings.sort(key=lambda x: x[0])
        n = len(target_dates_ratings)
        if n >= MIN_TREND_REVIEWS * 2:
            mid = n // 2
            older = target_dates_ratings[:mid]
            newer = target_dates_ratings[mid:]
            older_avg = sum(r for _, r in older) / len(older)
            newer_avg = sum(r for _, r in newer) / len(newer)
            trend_delta = round(newer_avg - older_avg, 2)

    if trend_delta != 0 or (target_recent["count"] >= MIN_TREND_REVIEWS and target_prev["count"] >= MIN_TREND_REVIEWS):
        if trend_delta > 0.1:
            trend = "up"
        elif trend_delta < -0.1:
            trend = "down"
        else:
            trend = "stable"

    # Reasons for target variant (recent window)
    recent_total = variant_recent.get(target_variant, {"count": 0})["count"]
    recent_reasons = variant_reason_recent.get(target_variant, Counter())
    total_reasons = variant_reason_counts.get(target_variant, Counter())

    # Choose window: if recent has enough data, use recent; else fallback to all
    use_recent = recent_total >= 8
    reason_counts = recent_reasons if use_recent else total_reasons
    reason_total = sum(reason_counts.values()) or 0

    # --- LLM classification (replaces rule-based if available) ---
    llm_reason_counts = None
    if use_llm and negative_texts_for_llm:
        target_negative = [
            {"index": i, "text": t["text"]}
            for i, t in enumerate(negative_texts_for_llm)
            if t["variant"] == target_variant or target_variant == "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä"
        ]
        if target_negative:
            print(f"LLM classify: {len(target_negative)} negative reviews for variant '{target_variant}'")
            reason_defs = {k: {"label": v["label"], "emoji": v["emoji"]} for k, v in REASONS.items()}
            llm_reason_counts = llm_classify_reasons(target_negative, category, reason_defs)
            if llm_reason_counts is not None:
                print(f"LLM classify: OK ‚Äî {llm_reason_counts}")
            else:
                print(f"LLM classify: failed, using rule-based fallback")

    # Build reason_rows from LLM or rule-based
    if llm_reason_counts is not None:
        reason_counts_final = llm_reason_counts
        reason_total = sum(reason_counts_final.values()) or 0
    else:
        reason_counts_final = dict(reason_counts.most_common()) if reason_counts else {}
        reason_total = sum(reason_counts_final.values()) or 0

    reason_rows = []
    if reason_total:
        sorted_reasons = sorted(reason_counts_final.items(), key=lambda x: x[1], reverse=True)
        for key, cnt in sorted_reasons:
            if key == "other":
                label = "–ü—Ä–æ—á–µ–µ"
                emoji = "‚ùì"
            elif key in REASONS:
                label = REASONS[key]["label"]
                emoji = REASONS[key]["emoji"]
            else:
                # LLM might return a key not in REASONS ‚Äî use it as-is
                label = key
                emoji = "‚ùì"
            reason_rows.append({
                "label": label,
                "emoji": emoji,
                "count": cnt,
                "share": round(cnt / reason_total * 100),
            })

    # Comparison with other variants for same reasons
    compare_variants = [v for v in valid_colors if v != target_variant]
    compare_variants = sorted(compare_variants, key=lambda k: variant_stats[k]["count"], reverse=True)[:2]
    compare_rows = []
    for v in compare_variants:
        v_total = variant_recent[v]["count"] if use_recent else variant_stats[v]["count"]
        if v_total == 0:
            compare_rows.append({"name": v, "share": None})
            continue
        v_reasons = variant_reason_recent[v] if use_recent else variant_reason_counts[v]
        v_reason_total = sum(v_reasons.values()) or 0
        share = round(v_reason_total / max(v_total, 1) * 100) if v_reason_total else 0
        compare_rows.append({"name": v, "share": share})

    article = None
    if feedbacks:
        article = feedbacks[0].get("article")

    data_window = f"{WINDOW_DAYS} –¥–Ω–µ–π" if use_recent else "12 –º–µ—Å—è—Ü–µ–≤"

    # Check if there's a statistically significant signal
    has_signal = False
    if target_variant and target_variant != "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä":
        others_for_gap = [v for v in valid_colors if v != target_variant and variant_stats[v]["count"] >= MIN_REVIEWS_FOR_SIGNAL]
        if others_for_gap and target_stats["count"] >= MIN_REVIEWS_FOR_SIGNAL:
            others_sum = sum(variant_stats[v]["sum"] for v in others_for_gap)
            others_cnt = sum(variant_stats[v]["count"] for v in others_for_gap)
            others_avg_val = others_sum / others_cnt if others_cnt else 0
            gap = round(others_avg_val - target_avg, 1)
            has_signal = gap >= MIN_GAP_FOR_SIGNAL

    main_reason = None
    if reason_rows:
        main_reason = reason_rows[0]["label"]

    if has_signal:
        signal_title = f"‚ö† –ü—Ä–æ–±–ª–µ–º–∞ –≤ –≤–∞—Ä–∏–∞–Ω—Ç–µ: {target_variant}"
        summary_lines = [
            f"–†–µ–π—Ç–∏–Ω–≥ {target_avg} ‚Äî –Ω–∞ {round(gap, 2)} –Ω–∏–∂–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤",
        ]
        if main_reason:
            summary_lines.append(f"–ü—Ä–∏—á–∏–Ω–∞: {main_reason}")
        summary_lines.append("–†–∏—Å–∫ –ø–∞–¥–µ–Ω–∏—è —Ä–µ–π—Ç–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏")
        signal_summary = "\n".join(summary_lines)
    elif target_variant and target_variant != "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä":
        signal_title = "‚úì –í–∞—Ä–∏–∞–Ω—Ç—ã –≤ –Ω–æ—Ä–º–µ"
        signal_summary = f"–†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞ (–º–µ–Ω–µ–µ {MIN_GAP_FOR_SIGNAL})"
    else:
        signal_title = "‚ö† –ü—Ä–æ–±–ª–µ–º–∞ –≤ —Ç–æ–≤–∞—Ä–µ"
        signal_summary = "–ü–æ–≤—Ç–æ—Ä—è—é—â–∞—è—Å—è –ø—Ä–∏—á–∏–Ω–∞, –Ω–µ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å"

    # –ü–æ–¥—Å—á—ë—Ç –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ –∏ –Ω–µ–æ—Ç–≤–µ—á–µ–Ω–Ω—ã—Ö
    negative_count = sum(1 for f in feedbacks if float(f.get("valuation") or 0) <= 3)
    unanswered_count = sum(1 for f in feedbacks if not (f.get("answer_text") or "").strip())
    neg_rate = negative_count / max(total, 1)

    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏
    risk_items = []
    if neg_rate > 0.15:
        risk_items.append(f"–í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –Ω–µ–≥–∞—Ç–∏–≤–∞: {round(neg_rate * 100)}% –æ—Ç–∑—ã–≤–æ–≤ —Å –æ—Ü–µ–Ω–∫–æ–π 1-3")
    elif neg_rate > 0.08:
        risk_items.append(f"–ü–æ–≤—ã—à–µ–Ω–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –Ω–µ–≥–∞—Ç–∏–≤–∞: {round(neg_rate * 100)}% –æ—Ç–∑—ã–≤–æ–≤ —Å –æ—Ü–µ–Ω–∫–æ–π 1-3")
    else:
        risk_items.append(f"–£—Ä–æ–≤–µ–Ω—å –Ω–µ–≥–∞—Ç–∏–≤–∞ –≤ –Ω–æ—Ä–º–µ: {round(neg_rate * 100)}% –æ—Ç–∑—ã–≤–æ–≤ —Å –æ—Ü–µ–Ω–∫–æ–π 1-3")

    if target_avg < 4.0 and target_variant and target_variant != "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä":
        risk_items.append(f"–†–µ–π—Ç–∏–Ω–≥ –≤–∞—Ä–∏–∞–Ω—Ç–∞ ¬´{target_variant}¬ª –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–∏–π: {target_avg}")
    elif target_avg < 4.5 and target_variant and target_variant != "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä":
        risk_items.append(f"–†–µ–π—Ç–∏–Ω–≥ –≤–∞—Ä–∏–∞–Ω—Ç–∞ ¬´{target_variant}¬ª –Ω–∏–∂–µ —Å—Ä–µ–¥–Ω–µ–≥–æ: {target_avg}")

    if trend == "down":
        risk_items.append(f"–¢—Ä–µ–Ω–¥ —É—Ö—É–¥—à–∞–µ—Ç—Å—è: {trend_delta} –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {WINDOW_DAYS} –¥–Ω–µ–π")

    if unanswered_count > 0:
        unanswered_pct = round(unanswered_count / max(total, 1) * 100)
        risk_items.append(f"{unanswered_count} –æ—Ç–∑—ã–≤–æ–≤ –±–µ–∑ –æ—Ç–≤–µ—Ç–∞ ({unanswered_pct}%)")

    if not risk_items:
        risk_items.append("–°–µ—Ä—å—ë–∑–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")

    # –ö–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ-–∑–∞–≤–∏—Å–∏–º—ã–µ —Ç–µ–∫—Å—Ç—ã
    category_labels = {
        "flashlight": {"type": "–≤–∞—Ä–∏–∞–Ω—Ç—É", "item": "–≤–∞—Ä–∏–∞–Ω—Ç–∞"},
        "clothing": {"type": "–≤–∞—Ä–∏–∞–Ω—Ç—É", "item": "–≤–∞—Ä–∏–∞–Ω—Ç–∞"},
        "electronics": {"type": "–≤–∞—Ä–∏–∞–Ω—Ç—É", "item": "–≤–∞—Ä–∏–∞–Ω—Ç–∞"},
        "pet_food": {"type": "—Ç–æ–≤–∞—Ä—É", "item": "—Ç–æ–≤–∞—Ä–∞"},
    }
    cat_label = category_labels.get(category, {"type": "–≤–∞—Ä–∏–∞–Ω—Ç—É", "item": "–≤–∞—Ä–∏–∞–Ω—Ç–∞"})

    # --- Deep analysis: root cause + strategy + actions + reply ---
    deep = None
    if use_llm and target_variant and target_variant != "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä" and reason_rows:
        try:
            review_samples = [
                t["text"][:300] for t in negative_texts_for_llm
                if t["variant"] == target_variant
            ][:10]
            other_vars = [
                {"name": v, "rating": round(avg(variant_stats[v]), 2), "count": variant_stats[v]["count"]}
                for v in valid_colors
                if v != target_variant and variant_stats[v]["count"] >= MIN_REVIEWS_FOR_SIGNAL
            ]
            # Build card description for LLM context
            card_description = None
            if wb_card:
                card_description = wb_card.get("description", "")
                if wb_card.get("options"):
                    card_description += "\n–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: " + wb_card["options"]

            deep = llm_deep_analysis(
                product_name=product_name or (wb_card or {}).get("imt_name", ""),
                category=category,
                target_variant=target_variant,
                target_rating=target_avg,
                target_count=target_stats["count"],
                other_variants=other_vars,
                reason_rows=reason_rows,
                review_samples=review_samples,
                card_description=card_description,
                questions=questions,
            )
            if deep:
                print(f"LLM deep_analysis: OK ‚Äî type={deep['root_cause'].get('type')}, strategy={deep['strategy'].get('title')}")
            else:
                print("LLM deep_analysis: returned None, using separate LLM calls")
        except Exception as e:
            print(f"LLM deep_analysis: error {e}, using separate LLM calls")

    # Build actions and reply from deep analysis or fallback
    if deep:
        actions_items = deep.get("actions", [])[:3]
        reply_text = deep.get("reply", "")
        risk_explanation = deep.get("root_cause", {}).get("explanation", risk_items)
        risk_conclusion = deep.get("root_cause", {}).get("conclusion")
        strategy_title = deep.get("strategy", {}).get("title")
        actions_desc = deep.get("strategy", {}).get("description")
    else:
        actions_items = _get_actions_with_fallback(use_llm, category, target_variant, reason_rows)
        reply_text = _get_reply_with_fallback(use_llm, category, main_reason, product_name, target_variant)
        risk_explanation = risk_items
        risk_conclusion = None
        strategy_title = None
        actions_desc = None

    # --- Response speed calculation (from data, not LLM) ---
    response_times_all = []
    response_times_neg = []
    for f in feedbacks:
        fb_dt = parse_date(f.get("fb_created_at") or "")
        ans_dt = parse_date(f.get("answer_created_at") or "")
        if fb_dt and ans_dt and ans_dt > fb_dt:
            delta_hours = (ans_dt - fb_dt).total_seconds() / 3600
            response_times_all.append(delta_hours)
            rating = int(f.get("valuation") or 0)
            if rating <= 3:
                response_times_neg.append(delta_hours)

    response_speed = None
    if response_times_all:
        sorted_all = sorted(response_times_all)
        sorted_neg = sorted(response_times_neg) if response_times_neg else []
        response_speed = {
            "all_median_hours": round(sorted_all[len(sorted_all) // 2], 1),
            "all_avg_hours": round(sum(sorted_all) / len(sorted_all), 1),
            "all_count": len(sorted_all),
            "neg_median_hours": round(sorted_neg[len(sorted_neg) // 2], 1) if sorted_neg else None,
            "neg_avg_hours": round(sum(sorted_neg) / len(sorted_neg), 1) if sorted_neg else None,
            "neg_count": len(sorted_neg),
            "max_hours": round(max(sorted_all), 1),
            "same_day_count": sum(1 for h in sorted_all if h < 24),
            "slow_count": sum(1 for h in sorted_all if h >= 24 * 7),
        }
        print(f"[Response speed] all median: {response_speed['all_median_hours']}h, "
              f"neg median: {response_speed['neg_median_hours']}h, "
              f"max: {response_speed['max_hours']}h")

    # --- Communication quality analysis ---
    communication = None
    if use_llm:
        try:
            communication = llm_analyze_communication(
                feedbacks=feedbacks,
                product_name=product_name or (wb_card or {}).get("imt_name", ""),
            )
            if communication:
                print(f"[Communication] OK ‚Äî quality_score: {communication['quality_score']}/10, "
                      f"verdict: {(communication.get('verdict') or '')[:80]}")
            else:
                print("[Communication] LLM returned None")
        except Exception as e:
            print(f"[Communication] error: {e}")

    # --- Money loss estimation ---
    money_loss = None
    # Use average price from CDN price history (more accurate), fall back to card price
    card_price = (wb_card or {}).get("price")
    price = card_price
    avg_price_3m = None
    if nm_id:
        price_history = fetch_wb_price_history(nm_id)
        avg_price_3m = avg_price_from_history(price_history, months=3)
        if avg_price_3m:
            print(f"[Money loss] Using avg price from history: {avg_price_3m}‚ÇΩ (card price: {card_price}‚ÇΩ)")
            price = avg_price_3m
    if communication and price:
        # Calculate period in months
        dates = [parse_date(f.get("fb_created_at") or "") for f in feedbacks]
        dates = [d for d in dates if d]
        if dates:
            period_days = (max(dates) - min(dates)).days
            period_months = max(1, round(period_days / 30))

            quality_score = communication.get("quality_score", 5)
            money_loss = calculate_money_loss(
                review_count=len(feedbacks),
                period_months=period_months,
                price_rub=price,
                quality_score=quality_score
            )
            if money_loss:
                if card_price:
                    money_loss["card_price"] = round(card_price)
                if avg_price_3m:
                    money_loss["avg_price_3m"] = round(avg_price_3m)
                print(f"[Money loss] Est. loss: {money_loss['loss_per_month_min']:,} - "
                      f"{money_loss['loss_per_month_max']:,}‚ÇΩ/–º–µ—Å "
                      f"(price: {price}‚ÇΩ, period: {period_months}–º–µ—Å, {len(feedbacks)} reviews)")
            else:
                print("[Money loss] Calculation skipped (no price)")
        else:
            print("[Money loss] Calculation skipped (no dates)")

    result = {
        "header": {
            "title": f"–ê—Ä—Ç–∏–∫—É–ª {article or ''} ¬∑ –†–∏—Å–∫ –ø–æ {cat_label['type']}",
            "subtitle": f"WB ¬∑ {len(feedbacks)} –æ—Ç–∑—ã–≤–æ–≤ ¬∑ —Ä–µ–π—Ç–∏–Ω–≥ {rating} ¬∑ –¥–∞–Ω–Ω—ã–µ –∑–∞ {data_window}",
            "rating": rating,
            "feedback_count": len(feedbacks),
            "analyzed_count": len(feedbacks),
            "unanswered_count": unanswered_count,
            "category": category,
            "product_name": product_name or (wb_card or {}).get("imt_name", ""),
        },
        "signal": {
            "title": signal_title,
            "summary": signal_summary,
            "scores": sorted(
                [
                    {
                        "label": v,
                        "value": avg(variant_stats[v]),
                        "count": variant_stats[v]["count"],
                        "is_target": v == target_variant,
                        "trend": trend if v == target_variant else None,
                        "trend_delta": trend_delta if v == target_variant else None,
                    }
                    for v in valid_colors
                    if variant_stats[v]["count"] >= MIN_REVIEWS_FOR_SIGNAL
                ],
                key=lambda x: x["value"],
            ),
            "meta": f"{target_stats['count']} –æ—Ç–∑—ã–≤–æ–≤, –¥–æ–≤–µ—Ä–∏–µ: {'–≤—ã—Å–æ–∫–æ–µ' if target_stats['count'] >= 20 else '—Å—Ä–µ–¥–Ω–µ–µ' if target_stats['count'] >= 10 else '–Ω–∏–∑–∫–æ–µ'}",
            "trend_info": f"–ó–∞ {WINDOW_DAYS} –¥–Ω: {'+' if trend_delta > 0 else ''}{trend_delta}" if trend else None,
        },
        "reasons": {
            "title": f"–ü–æ—á–µ–º—É –∏–º–µ–Ω–Ω–æ —ç—Ç–æ—Ç {cat_label['type'].replace('—É', '')} –ø—Ä–æ—Å–µ–¥–∞–µ—Ç" if target_variant and target_variant != "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä" else "–ü—Ä–∏—á–∏–Ω—ã –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤",
            "items": reason_rows,
            "reviews": [
                r for r in negative_review_samples
                if r["variant"] == target_variant or target_variant == "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä"
            ][:5],
            "cta": f"–ü–æ–∫–∞–∑–∞—Ç—å –æ—Ç–∑—ã–≤—ã ({target_stats['count']})",
        },
        "compare": {
            "title": "–≠—Ç–æ –∞–Ω–æ–º–∞–ª–∏—è –∏–ª–∏ –Ω–æ—Ä–º–∞",
            "rows": compare_rows,
            "conclusion": f"–ü—Ä–æ–±–ª–µ–º–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞ –¥–ª—è –≤–∞—Ä–∏–∞–Ω—Ç–∞ ¬´{target_variant}¬ª" if target_variant and target_variant != "–û–¥–∏–Ω —Ç–æ–≤–∞—Ä" else "–ü—Ä–æ–±–ª–µ–º–∞ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫–æ –≤—Å–µ–º—É —Ç–æ–≤–∞—Ä—É",
        },
        "risk": {
            "title": "–í—ã–≤–æ–¥—ã",
            "items": risk_explanation,
            "conclusion": risk_conclusion,
            "note": f"–†–∞—Å—á—ë—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ {total} –æ—Ç–∑—ã–≤–æ–≤ –∑–∞ {data_window}",
        },
        "actions": {
            "title": "–ß—Ç–æ –¥–µ–ª–∞—Ç—å",
            "strategy": strategy_title,
            "description": actions_desc,
            "items": actions_items,
            "status": "‚è≥ –ü–æ–¥ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ–º, –ø–µ—Ä–µ—Å—á–µ—Ç —Å–∏–≥–Ω–∞–ª–∞ —á–µ—Ä–µ–∑ 7 –¥–Ω–µ–π",
        },
        "reply": {
            "title": "–ß–µ—Ä–Ω–æ–≤–∏–∫ –æ—Ç–≤–µ—Ç–∞ (–∞–≤—Ç–æ)",
            "text": reply_text,
            "note": "–û—Ç–≤–µ—Ç –Ω–µ —Å–Ω–∏–∂–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É, –Ω–æ —Å–Ω–∏–∂–∞–µ—Ç –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –Ω–µ–≥–∞—Ç–∏–≤.",
        },
        "questions": {
            "count": len(questions),
            "unanswered_count": sum(1 for q in questions if not q.get("answer_text")),
            "samples": [
                {"text": q["qs_text"][:200], "answered": bool(q.get("answer_text"))}
                for q in questions[:5]
            ],
        },
        "response_speed": response_speed,
        "communication": communication,
        "money_loss": money_loss,
        "price": price,
    }

    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)


if __name__ == "__main__":
    main()
